{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vibe Coding: Real-World Data Cleaning Challenge\n",
    "\n",
    "## The Mission\n",
    "\n",
    "You're a Data Analyst at **TechSalary Insights**. Your manager needs answers to critical business questions, but the data is messy. Your job is to clean it and provide accurate insights.\n",
    "\n",
    "**The catch:** You must figure out how to clean the data yourself. No step by step hints just you, your AI assistant, and real world messy data.\n",
    "\n",
    "---\n",
    "\n",
    "## The Dataset: Ask A Manager Salary Survey 2021\n",
    "\n",
    "**Location:** `../Week-02-Pandas-Part-2-and-DS-Overview/data/Ask A Manager Salary Survey 2021 (Responses) - Form Responses 1.tsv`\n",
    "\n",
    "This is **real survey data** from Ask A Manager's 2021 salary survey with over 28,000 responses from working professionals. The data comes from this survey: https://www.askamanager.org/2021/04/how-much-money-do-you-make-4.html\n",
    "\n",
    "**Why this dataset is perfect for vibe coding:**\n",
    "- Real human responses (inconsistent formatting)\n",
    "- Multiple currencies and formats  \n",
    "- Messy job titles and location data\n",
    "- Missing and invalid entries\n",
    "- Requires business judgment calls\n",
    "\n",
    "---\n",
    "\n",
    "## Your Business Questions\n",
    "\n",
    "Answer these **exact questions** with clean data. There's only one correct answer for each:\n",
    "\n",
    "### Core Questions (Required):\n",
    "1. **What is the median salary for Software Engineers in the United States?** \n",
    "2. **Which US state has the highest average salary for tech workers?**\n",
    "3. **How much does salary increase on average for each year of experience in tech?**\n",
    "4. **Which industry (besides tech) has the highest median salary?**\n",
    "\n",
    "### Bonus Questions (If time permits):\n",
    "5. **What's the salary gap between men and women in tech roles?**\n",
    "6. **Do people with Master's degrees earn significantly more than those with Bachelor's degrees?**\n",
    "\n",
    "**Success Criteria:** Your final answers will be compared against the \"official\" results. Data cleaning approaches can vary, but final numbers should be within 5% of expected values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Your Work Starts Here\n",
    "\n",
    "## Step 0: Create Your Plan\n",
    "**Before writing any code, use Cursor to create your todo plan. Then paste it here:**\n",
    "\n",
    "## My Data Cleaning Plan\n",
    "\n",
    "### Phase 1: Initial Data Loading & Exploration\n",
    "- [ ] Load the TSV file with proper separator\n",
    "- [ ] Check the shape of the dataset (rows, columns)\n",
    "- [ ] Examine column names and data types\n",
    "- [ ] Look at first/last few rows to understand structure\n",
    "- [ ] Check for missing values across all columns\n",
    "- [ ] Get summary statistics for numeric columns\n",
    "\n",
    "### Phase 2: Column Standardization & Cleanup\n",
    "- [ ] Rename columns to shorter, code-friendly names (e.g., 'What industry do you work in?' ‚Üí 'industry')\n",
    "- [ ] Identify which columns are needed for analysis:\n",
    "  - Timestamp (for date filtering)\n",
    "  - Age\n",
    "  - Industry\n",
    "  - Job title\n",
    "  - Salary\n",
    "  - Currency\n",
    "  - Country\n",
    "  - State (for US respondents)\n",
    "  - Years of experience (overall and field-specific)\n",
    "  - Education level\n",
    "  - Gender\n",
    "- [ ] Drop unnecessary columns (additional context fields, etc.)\n",
    "\n",
    "### Phase 3: Critical Data Cleaning - Currency & Salary\n",
    "- [ ] **CURRENCY STANDARDIZATION:**\n",
    "  - Filter to USD only (since questions focus on US data)\n",
    "  - Or implement currency conversion if needed for non-tech industries\n",
    "- [ ] **SALARY CLEANING:**\n",
    "  - Convert salary column to numeric (handle text, commas, etc.)\n",
    "  - Remove obviously invalid salaries (0, negative, unrealistic values like >$1M or <$10k)\n",
    "  - Handle missing salary values (drop rows)\n",
    "  - Check for outliers and decide on reasonable bounds\n",
    "\n",
    "### Phase 4: Geographic Data Cleaning\n",
    "- [ ] **COUNTRY STANDARDIZATION:**\n",
    "  - Standardize US variations: 'US', 'USA', 'United States', 'usa', 'U.S.', etc. ‚Üí 'US'\n",
    "  - Keep track of other countries for industry comparison\n",
    "- [ ] **STATE CLEANING (US only):**\n",
    "  - Check for state name variations and inconsistencies\n",
    "  - Handle missing state data\n",
    "  - Standardize state names (full names vs abbreviations)\n",
    "\n",
    "### Phase 5: Industry & Job Title Cleaning\n",
    "- [ ] **INDUSTRY:**\n",
    "  - Identify exact value for tech/computing industry\n",
    "  - Create tech industry filter\n",
    "  - Check unique industries for non-tech analysis\n",
    "- [ ] **JOB TITLES (for Software Engineer analysis):**\n",
    "  - Find variations: 'Software Engineer', 'software engineer', 'Software Developer', etc.\n",
    "  - Create flexible matching (case-insensitive, contains 'software' and 'engineer')\n",
    "  - Consider related titles: 'Developer', 'SWE', 'Software Dev', etc.\n",
    "- [ ] **DATA QUALITY - SUSPICIOUS ENTRIES:**\n",
    "  - Identify suspicious job title + salary combinations\n",
    "  - Flag or remove obvious joke/fake entries like:\n",
    "    - Job titles: \"bum\", \"unemployed\", \"student\", \"none\", etc.\n",
    "    - Job titles with profanity or gibberish\n",
    "  - Consider reasonable salary ranges by job category (optional, but helpful)\n",
    "\n",
    "### Phase 6: Experience & Education Cleaning\n",
    "- [ ] **YEARS OF EXPERIENCE:**\n",
    "  - Convert text ranges to numeric values ('5-7 years' ‚Üí 6, '8-10 years' ‚Üí 9)\n",
    "  - Handle '1 year or less' ‚Üí 0.5 or 1\n",
    "  - Handle '21-30 years' or '31+ years'\n",
    "  - Create numeric field_experience column\n",
    "- [ ] **EDUCATION:**\n",
    "  - Standardize education levels\n",
    "  - Create Bachelor's vs Master's groups for comparison\n",
    "\n",
    "### Phase 7: Gender Data Cleaning (for bonus question)\n",
    "- [ ] Standardize gender values\n",
    "- [ ] Handle variations: 'Man', 'Woman', etc.\n",
    "- [ ] Decide how to handle non-binary/other for gap analysis\n",
    "\n",
    "### Phase 8: Date Filtering\n",
    "- [ ] Convert timestamp to datetime\n",
    "- [ ] Verify all data is from 2021 (survey year)\n",
    "- [ ] Filter if needed for specific time ranges\n",
    "\n",
    "### Phase 9: Answer Business Questions\n",
    "- [ ] **Q1: Median salary for Software Engineers in US**\n",
    "  - Filter: country='US', job_title contains 'software engineer', currency='USD'\n",
    "  - Calculate median\n",
    "- [ ] **Q2: Highest paying US state for tech workers**\n",
    "  - Filter: country='US', industry='Computing or Tech', currency='USD'\n",
    "  - Group by state, calculate mean salary\n",
    "  - Sort and find top state\n",
    "- [ ] **Q3: Salary increase per year of experience in tech**\n",
    "  - Filter: tech industry, US, USD\n",
    "  - Perform regression or correlation between experience and salary\n",
    "  - Calculate average increase per year\n",
    "- [ ] **Q4: Highest paying non-tech industry**\n",
    "  - Filter: exclude tech, USD only\n",
    "  - Group by industry, calculate median\n",
    "  - Find highest\n",
    "- [ ] **Q5 (Bonus): Gender pay gap in tech**\n",
    "  - Filter: tech roles, US, USD, gender='Man' or 'Woman'\n",
    "  - Compare median/mean salaries\n",
    "  - Calculate percentage difference\n",
    "- [ ] **Q6 (Bonus): Master's vs Bachelor's salary difference**\n",
    "  - Filter: education level, tech or all industries\n",
    "  - Compare median salaries\n",
    "  - Statistical significance test if needed\n",
    "\n",
    "### Phase 10: Validation & Quality Checks\n",
    "- [ ] Verify sample sizes for each analysis (ensure sufficient data)\n",
    "- [ ] Check for and document any assumptions made\n",
    "- [ ] Sanity check all final numbers (do they make sense?)\n",
    "- [ ] Document edge cases and how they were handled\n",
    "\n",
    "### Phase 11: Documentation\n",
    "- [ ] Document key decisions made during cleaning\n",
    "- [ ] Note any data quality issues discovered\n",
    "- [ ] Summarize findings in final section\n",
    "- [ ] List challenges and solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Data Loading and Exploration\n",
    "\n",
    "Start here! Load the dataset and get familiar with what you're working with.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PHASE 1: DATA LOADING & EXPLORATION\n",
      "================================================================================\n",
      "\n",
      "üìä Dataset Shape: 28,062 rows √ó 18 columns\n",
      "\n",
      "üìã Column Names and Data Types:\n",
      "--------------------------------------------------------------------------------\n",
      "Timestamp                                                                                                                                                                                                                                object\n",
      "How old are you?                                                                                                                                                                                                                         object\n",
      "What industry do you work in?                                                                                                                                                                                                            object\n",
      "Job title                                                                                                                                                                                                                                object\n",
      "If your job title needs additional context, please clarify here:                                                                                                                                                                         object\n",
      "What is your annual salary? (You'll indicate the currency in a later question. If you are part-time or hourly, please enter an annualized equivalent -- what you would earn if you worked the job 40 hours a week, 52 weeks a year.)     object\n",
      "How much additional monetary compensation do you get, if any (for example, bonuses or overtime in an average year)? Please only include monetary compensation here, not the value of benefits.                                          float64\n",
      "Please indicate the currency                                                                                                                                                                                                             object\n",
      "If \"Other,\" please indicate the currency here:                                                                                                                                                                                           object\n",
      "If your income needs additional context, please provide it here:                                                                                                                                                                         object\n",
      "What country do you work in?                                                                                                                                                                                                             object\n",
      "If you're in the U.S., what state do you work in?                                                                                                                                                                                        object\n",
      "What city do you work in?                                                                                                                                                                                                                object\n",
      "How many years of professional work experience do you have overall?                                                                                                                                                                      object\n",
      "How many years of professional work experience do you have in your field?                                                                                                                                                                object\n",
      "What is your highest level of education completed?                                                                                                                                                                                       object\n",
      "What is your gender?                                                                                                                                                                                                                     object\n",
      "What is your race? (Choose all that apply.)                                                                                                                                                                                              object\n",
      "dtype: object\n",
      "\n",
      "üëÄ First 5 Rows:\n",
      "--------------------------------------------------------------------------------\n",
      "            Timestamp How old are you?  What industry do you work in?  \\\n",
      "0  4/27/2021 11:02:10            25-34   Education (Higher Education)   \n",
      "1  4/27/2021 11:02:22            25-34              Computing or Tech   \n",
      "2  4/27/2021 11:02:38            25-34  Accounting, Banking & Finance   \n",
      "3  4/27/2021 11:02:41            25-34                     Nonprofits   \n",
      "4  4/27/2021 11:02:42            25-34  Accounting, Banking & Finance   \n",
      "\n",
      "                                  Job title  \\\n",
      "0        Research and Instruction Librarian   \n",
      "1  Change & Internal Communications Manager   \n",
      "2                      Marketing Specialist   \n",
      "3                           Program Manager   \n",
      "4                        Accounting Manager   \n",
      "\n",
      "  If your job title needs additional context, please clarify here:  \\\n",
      "0                                                NaN                 \n",
      "1                                                NaN                 \n",
      "2                                                NaN                 \n",
      "3                                                NaN                 \n",
      "4                                                NaN                 \n",
      "\n",
      "  What is your annual salary? (You'll indicate the currency in a later question. If you are part-time or hourly, please enter an annualized equivalent -- what you would earn if you worked the job 40 hours a week, 52 weeks a year.)  \\\n",
      "0                                             55,000                                                                                                                                                                                     \n",
      "1                                             54,600                                                                                                                                                                                     \n",
      "2                                             34,000                                                                                                                                                                                     \n",
      "3                                             62,000                                                                                                                                                                                     \n",
      "4                                             60,000                                                                                                                                                                                     \n",
      "\n",
      "   How much additional monetary compensation do you get, if any (for example, bonuses or overtime in an average year)? Please only include monetary compensation here, not the value of benefits.  \\\n",
      "0                                                0.0                                                                                                                                                \n",
      "1                                             4000.0                                                                                                                                                \n",
      "2                                                NaN                                                                                                                                                \n",
      "3                                             3000.0                                                                                                                                                \n",
      "4                                             7000.0                                                                                                                                                \n",
      "\n",
      "  Please indicate the currency  \\\n",
      "0                          USD   \n",
      "1                          GBP   \n",
      "2                          USD   \n",
      "3                          USD   \n",
      "4                          USD   \n",
      "\n",
      "  If \"Other,\" please indicate the currency here:   \\\n",
      "0                                             NaN   \n",
      "1                                             NaN   \n",
      "2                                             NaN   \n",
      "3                                             NaN   \n",
      "4                                             NaN   \n",
      "\n",
      "  If your income needs additional context, please provide it here:  \\\n",
      "0                                                NaN                 \n",
      "1                                                NaN                 \n",
      "2                                                NaN                 \n",
      "3                                                NaN                 \n",
      "4                                                NaN                 \n",
      "\n",
      "  What country do you work in?  \\\n",
      "0                United States   \n",
      "1               United Kingdom   \n",
      "2                           US   \n",
      "3                          USA   \n",
      "4                           US   \n",
      "\n",
      "  If you're in the U.S., what state do you work in? What city do you work in?  \\\n",
      "0                                     Massachusetts                    Boston   \n",
      "1                                               NaN                 Cambridge   \n",
      "2                                         Tennessee               Chattanooga   \n",
      "3                                         Wisconsin                 Milwaukee   \n",
      "4                                    South Carolina                Greenville   \n",
      "\n",
      "  How many years of professional work experience do you have overall?  \\\n",
      "0                                          5-7 years                    \n",
      "1                                       8 - 10 years                    \n",
      "2                                        2 - 4 years                    \n",
      "3                                       8 - 10 years                    \n",
      "4                                       8 - 10 years                    \n",
      "\n",
      "  How many years of professional work experience do you have in your field?  \\\n",
      "0                                          5-7 years                          \n",
      "1                                          5-7 years                          \n",
      "2                                        2 - 4 years                          \n",
      "3                                          5-7 years                          \n",
      "4                                          5-7 years                          \n",
      "\n",
      "  What is your highest level of education completed? What is your gender?  \\\n",
      "0                                    Master's degree                Woman   \n",
      "1                                     College degree           Non-binary   \n",
      "2                                     College degree                Woman   \n",
      "3                                     College degree                Woman   \n",
      "4                                     College degree                Woman   \n",
      "\n",
      "  What is your race? (Choose all that apply.)  \n",
      "0                                       White  \n",
      "1                                       White  \n",
      "2                                       White  \n",
      "3                                       White  \n",
      "4                                       White  \n",
      "\n",
      "üëÄ Last 5 Rows:\n",
      "--------------------------------------------------------------------------------\n",
      "                Timestamp How old are you?  What industry do you work in?  \\\n",
      "28057  7/12/2024 22:52:01            35-44                    Health care   \n",
      "28058  7/23/2024 17:51:03            25-34              Computing or Tech   \n",
      "28059  7/24/2024 12:22:58            18-24  Accounting, Banking & Finance   \n",
      "28060  7/26/2024 11:20:45            18-24              Computing or Tech   \n",
      "28061   8/20/2024 1:06:13            25-34                    Health care   \n",
      "\n",
      "                       Job title  \\\n",
      "28057               Veterinarian   \n",
      "28058          Systems Architect   \n",
      "28059  Risk Management Associate   \n",
      "28060                         IT   \n",
      "28061     Clinical physiologist    \n",
      "\n",
      "      If your job title needs additional context, please clarify here:  \\\n",
      "28057                                                NaN                 \n",
      "28058                                                NaN                 \n",
      "28059                                                NaN                 \n",
      "28060                                                NaN                 \n",
      "28061                                                NaN                 \n",
      "\n",
      "      What is your annual salary? (You'll indicate the currency in a later question. If you are part-time or hourly, please enter an annualized equivalent -- what you would earn if you worked the job 40 hours a week, 52 weeks a year.)  \\\n",
      "28057                                             135000                                                                                                                                                                                     \n",
      "28058                                             109000                                                                                                                                                                                     \n",
      "28059                                               1200                                                                                                                                                                                     \n",
      "28060                                               1700                                                                                                                                                                                     \n",
      "28061                                            1200000                                                                                                                                                                                     \n",
      "\n",
      "       How much additional monetary compensation do you get, if any (for example, bonuses or overtime in an average year)? Please only include monetary compensation here, not the value of benefits.  \\\n",
      "28057                                                NaN                                                                                                                                                \n",
      "28058                                                NaN                                                                                                                                                \n",
      "28059                                                0.0                                                                                                                                                \n",
      "28060                                               10.0                                                                                                                                                \n",
      "28061                                                NaN                                                                                                                                                \n",
      "\n",
      "      Please indicate the currency  \\\n",
      "28057                          USD   \n",
      "28058                          USD   \n",
      "28059                          USD   \n",
      "28060                          USD   \n",
      "28061                        Other   \n",
      "\n",
      "      If \"Other,\" please indicate the currency here:   \\\n",
      "28057                                             NaN   \n",
      "28058                                             NaN   \n",
      "28059                                             NaN   \n",
      "28060                                             NaN   \n",
      "28061                                             NGN   \n",
      "\n",
      "      If your income needs additional context, please provide it here:  \\\n",
      "28057                                                NaN                 \n",
      "28058                                                NaN                 \n",
      "28059                                                NaN                 \n",
      "28060                                                NaN                 \n",
      "28061                                                NaN                 \n",
      "\n",
      "      What country do you work in?  \\\n",
      "28057               United States    \n",
      "28058                          USA   \n",
      "28059                      Myanmar   \n",
      "28060                        Burma   \n",
      "28061                     Nigeria    \n",
      "\n",
      "      If you're in the U.S., what state do you work in?  \\\n",
      "28057                                          Missouri   \n",
      "28058                                           Georgia   \n",
      "28059                                          Colorado   \n",
      "28060                                               NaN   \n",
      "28061                                               NaN   \n",
      "\n",
      "      What city do you work in?  \\\n",
      "28057               Wentzville    \n",
      "28058                   Atlanta   \n",
      "28059                    Yangon   \n",
      "28060                    Yangon   \n",
      "28061                     Lagos   \n",
      "\n",
      "      How many years of professional work experience do you have overall?  \\\n",
      "28057                                      11 - 20 years                    \n",
      "28058                                          5-7 years                    \n",
      "28059                                        2 - 4 years                    \n",
      "28060                                        2 - 4 years                    \n",
      "28061                                        2 - 4 years                    \n",
      "\n",
      "      How many years of professional work experience do you have in your field?  \\\n",
      "28057                                      11 - 20 years                          \n",
      "28058                                          5-7 years                          \n",
      "28059                                        2 - 4 years                          \n",
      "28060                                     1 year or less                          \n",
      "28061                                        2 - 4 years                          \n",
      "\n",
      "      What is your highest level of education completed? What is your gender?  \\\n",
      "28057                 Professional degree (MD, JD, etc.)                Woman   \n",
      "28058                                     College degree                  Man   \n",
      "28059                                       Some college                  Man   \n",
      "28060                                       Some college                  Man   \n",
      "28061                                     College degree                Woman   \n",
      "\n",
      "      What is your race? (Choose all that apply.)  \n",
      "28057                                       White  \n",
      "28058                                       White  \n",
      "28059                     Asian or Asian American  \n",
      "28060                     Asian or Asian American  \n",
      "28061                   Black or African American  \n",
      "\n",
      "‚ùì Missing Values Count:\n",
      "--------------------------------------------------------------------------------\n",
      "                                                    Missing Count  Percentage\n",
      "If \"Other,\" please indicate the currency here:              27856   99.265911\n",
      "If your income needs additional context, please...          25020   89.159718\n",
      "If your job title needs additional context, ple...          20800   74.121588\n",
      "How much additional monetary compensation do yo...           7296   25.999572\n",
      "If you're in the U.S., what state do you work in?            5023   17.899651\n",
      "What is your highest level of education completed?            222    0.791105\n",
      "What is your race? (Choose all that apply.)                   177    0.630746\n",
      "What is your gender?                                          171    0.609365\n",
      "What city do you work in?                                      82    0.292210\n",
      "What industry do you work in?                                  74    0.263702\n",
      "Job title                                                       1    0.003564\n",
      "\n",
      "üìà Summary Statistics (Numeric Columns):\n",
      "--------------------------------------------------------------------------------\n",
      "       How much additional monetary compensation do you get, if any (for example, bonuses or overtime in an average year)? Please only include monetary compensation here, not the value of benefits.\n",
      "count                                       2.076600e+04                                                                                                                                             \n",
      "mean                                        1.816269e+04                                                                                                                                             \n",
      "std                                         8.340531e+05                                                                                                                                             \n",
      "min                                         0.000000e+00                                                                                                                                             \n",
      "25%                                         0.000000e+00                                                                                                                                             \n",
      "50%                                         2.000000e+03                                                                                                                                             \n",
      "75%                                         1.000000e+04                                                                                                                                             \n",
      "max                                         1.200000e+08                                                                                                                                             \n",
      "\n",
      "‚úÖ Phase 1 Complete!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ============================================\n",
    "# PHASE 1: Initial Data Loading & Exploration\n",
    "# ============================================\n",
    "\n",
    "# Load the TSV file with proper separator\n",
    "file_path = '../../Week-02-Pandas-Part-2-and-DS-Overview/data/Ask A Manager Salary Survey 2021 (Responses) - Form Responses 1.tsv'\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"PHASE 1: DATA LOADING & EXPLORATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Check the shape of the dataset\n",
    "print(f\"\\nüìä Dataset Shape: {df.shape[0]:,} rows √ó {df.shape[1]} columns\")\n",
    "\n",
    "# Examine column names and data types\n",
    "print(\"\\nüìã Column Names and Data Types:\")\n",
    "print(\"-\" * 80)\n",
    "print(df.dtypes)\n",
    "\n",
    "# Look at first few rows\n",
    "print(\"\\nüëÄ First 5 Rows:\")\n",
    "print(\"-\" * 80)\n",
    "print(df.head())\n",
    "\n",
    "# Look at last few rows to understand structure\n",
    "print(\"\\nüëÄ Last 5 Rows:\")\n",
    "print(\"-\" * 80)\n",
    "print(df.tail())\n",
    "\n",
    "# Check for missing values across all columns\n",
    "print(\"\\n‚ùì Missing Values Count:\")\n",
    "print(\"-\" * 80)\n",
    "missing_counts = df.isnull().sum()\n",
    "missing_pct = (df.isnull().sum() / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_counts,\n",
    "    'Percentage': missing_pct\n",
    "})\n",
    "print(missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False))\n",
    "\n",
    "# Get summary statistics for numeric columns\n",
    "print(\"\\nüìà Summary Statistics (Numeric Columns):\")\n",
    "print(\"-\" * 80)\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\n‚úÖ Phase 1 Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PHASE 2: COLUMN STANDARDIZATION & CLEANUP\n",
      "================================================================================\n",
      "\n",
      "üìù Original Column Names:\n",
      "--------------------------------------------------------------------------------\n",
      " 1. Timestamp\n",
      " 2. How old are you?\n",
      " 3. What industry do you work in?\n",
      " 4. Job title\n",
      " 5. If your job title needs additional context, please clarify here:\n",
      " 6. What is your annual salary? (You'll indicate the currency in a later question. If you are part-time or hourly, please enter an annualized equivalent -- what you would earn if you worked the job 40 hours a week, 52 weeks a year.)\n",
      " 7. How much additional monetary compensation do you get, if any (for example, bonuses or overtime in an average year)? Please only include monetary compensation here, not the value of benefits.\n",
      " 8. Please indicate the currency\n",
      " 9. If \"Other,\" please indicate the currency here: \n",
      "10. If your income needs additional context, please provide it here:\n",
      "11. What country do you work in?\n",
      "12. If you're in the U.S., what state do you work in?\n",
      "13. What city do you work in?\n",
      "14. How many years of professional work experience do you have overall?\n",
      "15. How many years of professional work experience do you have in your field?\n",
      "16. What is your highest level of education completed?\n",
      "17. What is your gender?\n",
      "18. What is your race? (Choose all that apply.)\n",
      "\n",
      "‚úÖ Columns renamed successfully!\n",
      "\n",
      "üìù New Column Names:\n",
      "--------------------------------------------------------------------------------\n",
      " 1. timestamp\n",
      " 2. age\n",
      " 3. industry\n",
      " 4. job_title\n",
      " 5. job_title_context\n",
      " 6. salary\n",
      " 7. additional_compensation\n",
      " 8. currency\n",
      " 9. other_currency\n",
      "10. income_context\n",
      "11. country\n",
      "12. state\n",
      "13. city\n",
      "14. years_experience_overall\n",
      "15. years_experience_field\n",
      "16. education\n",
      "17. gender\n",
      "18. race\n",
      "\n",
      "üìä Columns Needed for Analysis: 12\n",
      "--------------------------------------------------------------------------------\n",
      "  ‚úì timestamp\n",
      "  ‚úì age\n",
      "  ‚úì industry\n",
      "  ‚úì job_title\n",
      "  ‚úì salary\n",
      "  ‚úì currency\n",
      "  ‚úì country\n",
      "  ‚úì state\n",
      "  ‚úì years_experience_overall\n",
      "  ‚úì years_experience_field\n",
      "  ‚úì education\n",
      "  ‚úì gender\n",
      "\n",
      "üóëÔ∏è  Columns to Drop: 6\n",
      "--------------------------------------------------------------------------------\n",
      "  ‚úó job_title_context\n",
      "  ‚úó additional_compensation\n",
      "  ‚úó other_currency\n",
      "  ‚úó income_context\n",
      "  ‚úó city\n",
      "  ‚úó race\n",
      "\n",
      "üìâ Shape Before Cleanup: (28062, 18)\n",
      "üìà Shape After Cleanup: (28062, 12)\n",
      "\n",
      "‚úÖ Phase 2 Complete!\n",
      "‚ú® Cleaned dataset: 28,062 rows √ó 12 columns\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# PHASE 2: Column Standardization & Cleanup\n",
    "# ============================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"PHASE 2: COLUMN STANDARDIZATION & CLEANUP\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# First, let's see the original column names\n",
    "print(\"\\nüìù Original Column Names:\")\n",
    "print(\"-\" * 80)\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"{i:2}. {col}\")\n",
    "\n",
    "# Rename columns to shorter, code-friendly names\n",
    "column_mapping = {\n",
    "    'Timestamp': 'timestamp',\n",
    "    'How old are you?': 'age',\n",
    "    'What industry do you work in?': 'industry',\n",
    "    'Job title': 'job_title',\n",
    "    'If your job title needs additional context, please clarify here:': 'job_title_context',\n",
    "    'What is your annual salary? (You\\'ll indicate the currency in a later question. If you are part-time or hourly, please enter an annualized equivalent -- what you would earn if you worked the job 40 hours a week, 52 weeks a year.)': 'salary',\n",
    "    'How much additional monetary compensation do you get, if any (for example, bonuses or overtime in an average year)? Please only include monetary compensation here, not the value of benefits.': 'additional_compensation',\n",
    "    'Please indicate the currency': 'currency',\n",
    "    'If \"Other,\" please indicate the currency here: ': 'other_currency',\n",
    "    'If your income needs additional context, please provide it here:': 'income_context',\n",
    "    'What country do you work in?': 'country',\n",
    "    'If you\\'re in the U.S., what state do you work in?': 'state',\n",
    "    'What city do you work in?': 'city',\n",
    "    'How many years of professional work experience do you have overall?': 'years_experience_overall',\n",
    "    'How many years of professional work experience do you have in your field?': 'years_experience_field',\n",
    "    'What is your highest level of education completed?': 'education',\n",
    "    'What is your gender?': 'gender',\n",
    "    'What is your race? (Choose all that apply.)': 'race'\n",
    "}\n",
    "\n",
    "df = df.rename(columns=column_mapping)\n",
    "\n",
    "print(\"\\n‚úÖ Columns renamed successfully!\")\n",
    "print(\"\\nüìù New Column Names:\")\n",
    "print(\"-\" * 80)\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"{i:2}. {col}\")\n",
    "\n",
    "# Identify columns needed for analysis\n",
    "needed_columns = [\n",
    "    'timestamp',\n",
    "    'age',\n",
    "    'industry',\n",
    "    'job_title',\n",
    "    'salary',\n",
    "    'currency',\n",
    "    'country',\n",
    "    'state',\n",
    "    'years_experience_overall',\n",
    "    'years_experience_field',\n",
    "    'education',\n",
    "    'gender'\n",
    "]\n",
    "\n",
    "print(f\"\\nüìä Columns Needed for Analysis: {len(needed_columns)}\")\n",
    "print(\"-\" * 80)\n",
    "for col in needed_columns:\n",
    "    print(f\"  ‚úì {col}\")\n",
    "\n",
    "# Identify columns to drop\n",
    "columns_to_drop = [col for col in df.columns if col not in needed_columns]\n",
    "print(f\"\\nüóëÔ∏è  Columns to Drop: {len(columns_to_drop)}\")\n",
    "print(\"-\" * 80)\n",
    "for col in columns_to_drop:\n",
    "    print(f\"  ‚úó {col}\")\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df_clean = df[needed_columns].copy()\n",
    "\n",
    "print(f\"\\nüìâ Shape Before Cleanup: {df.shape}\")\n",
    "print(f\"üìà Shape After Cleanup: {df_clean.shape}\")\n",
    "\n",
    "print(\"\\n‚úÖ Phase 2 Complete!\")\n",
    "print(f\"‚ú® Cleaned dataset: {df_clean.shape[0]:,} rows √ó {df_clean.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PHASE 3: CURRENCY & SALARY CLEANING\n",
      "================================================================================\n",
      "\n",
      "üí± CURRENCY STANDARDIZATION\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìä Currency Distribution (Before Filtering):\n",
      "currency\n",
      "USD        23374\n",
      "CAD         1673\n",
      "GBP         1591\n",
      "EUR          643\n",
      "AUD/NZD      504\n",
      "Other        160\n",
      "CHF           37\n",
      "SEK           37\n",
      "JPY           23\n",
      "ZAR           16\n",
      "HKD            4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "‚úÖ Filtered to USD only\n",
      "   Rows before: 28,062\n",
      "   Rows after: 23,374\n",
      "   Rows removed: 4,688 (16.7%)\n",
      "\n",
      "üí∞ SALARY CLEANING\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìã Salary column type: object\n",
      "\n",
      "üëÄ Sample salary values (first 10):\n",
      "['55,000', '34,000', '62,000', '60,000', '62,000', '33,000', '50,000', '112,000', '45,000', '47,500']\n",
      "\n",
      "‚ùì Missing/Invalid salary values: 16,819\n",
      "   Rows removed: 16,819\n",
      "\n",
      "üìä Salary Statistics (Before Outlier Removal):\n",
      "count    6.555000e+03\n",
      "mean     9.410425e+04\n",
      "std      1.635568e+05\n",
      "min      0.000000e+00\n",
      "25%      5.600000e+04\n",
      "50%      7.900000e+04\n",
      "75%      1.121000e+05\n",
      "max      1.000000e+07\n",
      "Name: salary, dtype: float64\n",
      "\n",
      "üîç Salary Quality Check:\n",
      "   Zero or negative: 17\n",
      "   Unrealistically low (<$15k): 87\n",
      "   Unrealistically high (>$1M): 6\n",
      "\n",
      "   Sample high salaries with job titles:\n",
      "                  job_title      salary                       industry\n",
      "24955     Marketing Manager   1250000.0                    Health care\n",
      "26466  Inside sales manager   5000044.0                          Sales\n",
      "26558               Partner   1300000.0         Business or Consulting\n",
      "28021                   bum  10000000.0                            NaN\n",
      "28030               student   5000000.0  Accounting, Banking & Finance\n",
      "28043                  Lead   2600000.0              Computing or Tech\n",
      "\n",
      "‚úÖ Removed invalid salaries (outside $15k-$1M range)\n",
      "   Rows removed: 110\n",
      "\n",
      "üìà Final Salary Statistics:\n",
      "count      6445.000000\n",
      "mean      91765.447944\n",
      "std       54420.645411\n",
      "min       15000.000000\n",
      "25%       57000.000000\n",
      "50%       80000.000000\n",
      "75%      113000.000000\n",
      "max      954000.000000\n",
      "Name: salary, dtype: float64\n",
      "\n",
      "üìä Salary Percentiles:\n",
      "   10th percentile: $42,500\n",
      "   25th percentile: $57,000\n",
      "   50th percentile: $80,000\n",
      "   75th percentile: $113,000\n",
      "   90th percentile: $153,000\n",
      "   95th percentile: $180,800\n",
      "   99th percentile: $260,000\n",
      "\n",
      "üìç Statistical Outliers (IQR method - for reference only):\n",
      "   Lower fence: $-27,000\n",
      "   Upper fence: $197,000\n",
      "   Outliers detected: 241 (3.7%)\n",
      "   (Note: Not removing these - they may be legitimate high earners)\n",
      "\n",
      "‚úÖ Phase 3 Complete!\n",
      "‚ú® Cleaned dataset: 6,445 rows √ó 12 columns\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# PHASE 3: Critical Data Cleaning - Currency & Salary\n",
    "# ============================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"PHASE 3: CURRENCY & SALARY CLEANING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ----------------\n",
    "# CURRENCY STANDARDIZATION\n",
    "# ----------------\n",
    "print(\"\\nüí± CURRENCY STANDARDIZATION\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Check currency distribution\n",
    "print(\"\\nüìä Currency Distribution (Before Filtering):\")\n",
    "print(df_clean['currency'].value_counts())\n",
    "\n",
    "# Count rows before filtering\n",
    "rows_before_currency = len(df_clean)\n",
    "\n",
    "# Filter to USD only (since our questions focus on US data)\n",
    "df_clean = df_clean[df_clean['currency'] == 'USD'].copy()\n",
    "\n",
    "rows_after_currency = len(df_clean)\n",
    "rows_removed = rows_before_currency - rows_after_currency\n",
    "\n",
    "print(f\"\\n‚úÖ Filtered to USD only\")\n",
    "print(f\"   Rows before: {rows_before_currency:,}\")\n",
    "print(f\"   Rows after: {rows_after_currency:,}\")\n",
    "print(f\"   Rows removed: {rows_removed:,} ({(rows_removed/rows_before_currency)*100:.1f}%)\")\n",
    "\n",
    "# ----------------\n",
    "# SALARY CLEANING\n",
    "# ----------------\n",
    "print(\"\\nüí∞ SALARY CLEANING\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Check current salary data type and sample values\n",
    "print(f\"\\nüìã Salary column type: {df_clean['salary'].dtype}\")\n",
    "print(f\"\\nüëÄ Sample salary values (first 10):\")\n",
    "print(df_clean['salary'].head(10).tolist())\n",
    "\n",
    "# Convert salary to numeric (handle any text, commas, etc.)\n",
    "df_clean['salary'] = pd.to_numeric(df_clean['salary'], errors='coerce')\n",
    "\n",
    "# Check for missing values after conversion\n",
    "missing_salaries = df_clean['salary'].isnull().sum()\n",
    "print(f\"\\n‚ùì Missing/Invalid salary values: {missing_salaries:,}\")\n",
    "\n",
    "# Remove rows with missing salaries\n",
    "rows_before_missing = len(df_clean)\n",
    "df_clean = df_clean.dropna(subset=['salary']).copy()\n",
    "rows_after_missing = len(df_clean)\n",
    "print(f\"   Rows removed: {rows_before_missing - rows_after_missing:,}\")\n",
    "\n",
    "# Check salary distribution before filtering outliers\n",
    "print(f\"\\nüìä Salary Statistics (Before Outlier Removal):\")\n",
    "print(df_clean['salary'].describe())\n",
    "\n",
    "# Identify problematic salaries\n",
    "invalid_zero_negative = df_clean[df_clean['salary'] <= 0]\n",
    "unrealistically_low = df_clean[(df_clean['salary'] > 0) & (df_clean['salary'] < 15000)]\n",
    "unrealistically_high = df_clean[df_clean['salary'] > 1000000]\n",
    "\n",
    "print(f\"\\nüîç Salary Quality Check:\")\n",
    "print(f\"   Zero or negative: {len(invalid_zero_negative):,}\")\n",
    "print(f\"   Unrealistically low (<$15k): {len(unrealistically_low):,}\")\n",
    "print(f\"   Unrealistically high (>$1M): {len(unrealistically_high):,}\")\n",
    "\n",
    "if len(unrealistically_high) > 0:\n",
    "    print(f\"\\n   Sample high salaries with job titles:\")\n",
    "    high_sample = df_clean[df_clean['salary'] > 1000000][['job_title', 'salary', 'industry']].head(10)\n",
    "    print(high_sample.to_string())\n",
    "\n",
    "# Remove invalid salaries\n",
    "# Using $15,000 as lower bound (minimum wage equivalent)\n",
    "# Using $1,000,000 as upper bound (very high but not impossible)\n",
    "rows_before_bounds = len(df_clean)\n",
    "df_clean = df_clean[(df_clean['salary'] >= 15000) & (df_clean['salary'] <= 1000000)].copy()\n",
    "rows_after_bounds = len(df_clean)\n",
    "rows_removed_bounds = rows_before_bounds - rows_after_bounds\n",
    "\n",
    "print(f\"\\n‚úÖ Removed invalid salaries (outside $15k-$1M range)\")\n",
    "print(f\"   Rows removed: {rows_removed_bounds:,}\")\n",
    "\n",
    "# Final salary statistics\n",
    "print(f\"\\nüìà Final Salary Statistics:\")\n",
    "print(df_clean['salary'].describe())\n",
    "\n",
    "print(f\"\\nüìä Salary Percentiles:\")\n",
    "percentiles = [10, 25, 50, 75, 90, 95, 99]\n",
    "for p in percentiles:\n",
    "    value = df_clean['salary'].quantile(p/100)\n",
    "    print(f\"   {p}th percentile: ${value:,.0f}\")\n",
    "\n",
    "# Check for remaining outliers using IQR method (for information only)\n",
    "Q1 = df_clean['salary'].quantile(0.25)\n",
    "Q3 = df_clean['salary'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_fence = Q1 - 1.5 * IQR\n",
    "upper_fence = Q3 + 1.5 * IQR\n",
    "outliers_iqr = df_clean[(df_clean['salary'] < lower_fence) | (df_clean['salary'] > upper_fence)]\n",
    "\n",
    "print(f\"\\nüìç Statistical Outliers (IQR method - for reference only):\")\n",
    "print(f\"   Lower fence: ${lower_fence:,.0f}\")\n",
    "print(f\"   Upper fence: ${upper_fence:,.0f}\")\n",
    "print(f\"   Outliers detected: {len(outliers_iqr):,} ({(len(outliers_iqr)/len(df_clean))*100:.1f}%)\")\n",
    "print(f\"   (Note: Not removing these - they may be legitimate high earners)\")\n",
    "\n",
    "print(\"\\n‚úÖ Phase 3 Complete!\")\n",
    "print(f\"‚ú® Cleaned dataset: {df_clean.shape[0]:,} rows √ó {df_clean.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PHASE 4: GEOGRAPHIC DATA CLEANING\n",
      "================================================================================\n",
      "\n",
      "üåç COUNTRY STANDARDIZATION\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìä Top 20 Country Values (Before Standardization):\n",
      "country\n",
      "United States                2392\n",
      "USA                          2073\n",
      "US                            680\n",
      "United States                 236\n",
      "Usa                           180\n",
      "USA                           176\n",
      "U.S.                          139\n",
      "United States of America      128\n",
      "United states                 100\n",
      "usa                            47\n",
      "Us                             45\n",
      "united states                  36\n",
      "U.S.A.                         16\n",
      "United States of America       14\n",
      "U.S                            13\n",
      "us                             13\n",
      "United states                   8\n",
      "U.S.                            8\n",
      "Usa                             7\n",
      "United State                    5\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üìç Total unique country values: 107\n",
      "\n",
      "‚úÖ Standardized US country variations\n",
      "\n",
      "üìä Top 20 Country Values (After Standardization):\n",
      "country\n",
      "US                   6356\n",
      "Canada                  5\n",
      "Australia               4\n",
      "Denmark                 4\n",
      "üá∫üá∏                      3\n",
      "The United States       3\n",
      "Thailand                3\n",
      "Kenya                   3\n",
      "Colombia                3\n",
      "UnitedStates            2\n",
      "United Stares           2\n",
      "Japan                   2\n",
      "Israel                  2\n",
      "Philippines             2\n",
      "Switzerland             2\n",
      "Singapore               2\n",
      "United Sates            2\n",
      "South Korea             1\n",
      "Poland                  1\n",
      "The Netherlands         1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üá∫üá∏ US Records: 6,356 (98.6% of dataset)\n",
      "üåé Non-US Records: 89 (1.4% of dataset)\n",
      "\n",
      "\n",
      "üó∫Ô∏è  STATE CLEANING (US ONLY)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìä Working with 6,356 US records\n",
      "\n",
      "üìã State column info:\n",
      "   Total US records: 6,356\n",
      "   Records with state data: 6,337\n",
      "   Records missing state: 19\n",
      "   Missing state percentage: 0.3%\n",
      "\n",
      "üìç Unique state values: 80\n",
      "\n",
      "üìä Top 20 States (Before Cleaning):\n",
      "state\n",
      "California              725\n",
      "New York                588\n",
      "Massachusetts           396\n",
      "Texas                   366\n",
      "Illinois                316\n",
      "Washington              286\n",
      "Pennsylvania            265\n",
      "Ohio                    216\n",
      "District of Columbia    214\n",
      "Virginia                214\n",
      "Minnesota               186\n",
      "Florida                 186\n",
      "Oregon                  171\n",
      "Georgia                 171\n",
      "North Carolina          170\n",
      "Colorado                157\n",
      "Maryland                156\n",
      "Michigan                153\n",
      "Wisconsin               130\n",
      "New Jersey              117\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üîç Checking for problematic state entries...\n",
      "\n",
      "   States with >20 characters (15 unique):\n",
      "state\n",
      "District of Columbia, Virginia       3\n",
      "New Jersey, Pennsylvania             2\n",
      "Louisiana, Washington                1\n",
      "Delaware, Pennsylvania               1\n",
      "Illinois, North Carolina             1\n",
      "Indiana, Massachusetts               1\n",
      "District of Columbia, Washington     1\n",
      "Florida, New Hampshire, Wisconsin    1\n",
      "Pennsylvania, Rhode Island           1\n",
      "New York, Oregon, Vermont            1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "   States with commas (29 unique):\n",
      "state\n",
      "District of Columbia, Virginia       3\n",
      "New Jersey, New York                 3\n",
      "New Jersey, Pennsylvania             2\n",
      "District of Columbia, Washington     1\n",
      "Louisiana, Washington                1\n",
      "Illinois, North Carolina             1\n",
      "Indiana, Massachusetts               1\n",
      "Florida, New Hampshire, Wisconsin    1\n",
      "Pennsylvania, Rhode Island           1\n",
      "California, Oregon                   1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "‚úÖ State data cleaned (whitespace removed)\n",
      "\n",
      "üìä Top 20 States (After Cleaning):\n",
      "state\n",
      "California              725\n",
      "New York                588\n",
      "Massachusetts           396\n",
      "Texas                   366\n",
      "Illinois                316\n",
      "Washington              286\n",
      "Pennsylvania            265\n",
      "Ohio                    216\n",
      "District of Columbia    214\n",
      "Virginia                214\n",
      "Minnesota               186\n",
      "Florida                 186\n",
      "Oregon                  171\n",
      "Georgia                 171\n",
      "North Carolina          170\n",
      "Colorado                157\n",
      "Maryland                156\n",
      "Michigan                153\n",
      "Wisconsin               130\n",
      "New Jersey              117\n",
      "Name: count, dtype: int64\n",
      "\n",
      "‚ö†Ô∏è  Records with missing state data: 19\n",
      "   Decision: Keeping records with missing states for now.\n",
      "   Note: These will be excluded from state-specific analyses.\n",
      "\n",
      "‚úÖ Phase 4 Complete!\n",
      "‚ú® Cleaned dataset: 6,445 rows √ó 12 columns\n",
      "   US records: 6,356\n",
      "   US records with state: 6,337\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# PHASE 4: Geographic Data Cleaning\n",
    "# ============================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"PHASE 4: GEOGRAPHIC DATA CLEANING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ----------------\n",
    "# COUNTRY STANDARDIZATION\n",
    "# ----------------\n",
    "print(\"\\nüåç COUNTRY STANDARDIZATION\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Check current country values\n",
    "print(\"\\nüìä Top 20 Country Values (Before Standardization):\")\n",
    "print(df_clean['country'].value_counts().head(20))\n",
    "\n",
    "# Count unique country values\n",
    "print(f\"\\nüìç Total unique country values: {df_clean['country'].nunique()}\")\n",
    "\n",
    "# Standardize US variations to 'US'\n",
    "# Strategy: Use both explicit list AND regex patterns for comprehensive coverage\n",
    "\n",
    "# First, strip whitespace from all country values\n",
    "df_clean['country'] = df_clean['country'].str.strip()\n",
    "\n",
    "# Method 1: Explicit list for common variations\n",
    "us_variations = [\n",
    "    'United States',\n",
    "    'USA',\n",
    "    'US',\n",
    "    'usa',\n",
    "    'U.S.',\n",
    "    'U.S',\n",
    "    'us',\n",
    "    'United States of America',\n",
    "    'U.S.A.',\n",
    "    'U.S.A',\n",
    "    'Usa',\n",
    "    'united states',\n",
    "    'United states',\n",
    "    'UNITED STATES',\n",
    "    'America',\n",
    "    'United State',\n",
    "    'United  States',\n",
    "    'U. S.',\n",
    "    'U.s.',\n",
    "    'u.s.',\n",
    "    'Uniited States',\n",
    "    'Unites States'\n",
    "]\n",
    "\n",
    "df_clean['country'] = df_clean['country'].replace(us_variations, 'US')\n",
    "\n",
    "# Method 2: Regex patterns for additional variations\n",
    "# This catches typos, extra spaces, and other variations\n",
    "import re\n",
    "\n",
    "# Pattern explanation:\n",
    "# (?i) = case insensitive\n",
    "# ^...$ = must match entire string\n",
    "# \\s* = optional whitespace\n",
    "# Different patterns for different US variations\n",
    "\n",
    "regex_patterns = [\n",
    "    # Matches: \"u.s.\", \"U.S.\", \"u.s.a.\", \"U.S.A.\", etc. (with or without periods/spaces)\n",
    "    r'(?i)^u[\\s\\.]*s[\\s\\.]*a?[\\s\\.]*$',\n",
    "    \n",
    "    # Matches: \"united states\", \"united state\", \"unites states\", \"uniited states\", etc.\n",
    "    r'(?i)^uni[t]*ed\\s+states?(\\s+of\\s+america)?$',\n",
    "    \n",
    "    # Matches: \"usa\", \"us\" (with optional trailing characters)\n",
    "    r'(?i)^usa?[\\s\\-]*$',\n",
    "    \n",
    "    # Matches: \"america\" (careful with this one - only exact match)\n",
    "    r'(?i)^america$',\n",
    "    \n",
    "    # Matches common typos with extra spaces or characters\n",
    "    r'(?i)^u[\\s\\.\\-]*s[\\s\\.\\-]*$'\n",
    "]\n",
    "\n",
    "# Apply regex replacements\n",
    "for pattern in regex_patterns:\n",
    "    df_clean['country'] = df_clean['country'].str.replace(pattern, 'US', regex=True)\n",
    "\n",
    "# Final cleanup: strip again in case regex added spaces\n",
    "df_clean['country'] = df_clean['country'].str.strip()\n",
    "\n",
    "print(\"\\n‚úÖ Standardized US country variations\")\n",
    "\n",
    "# Check results\n",
    "print(\"\\nüìä Top 20 Country Values (After Standardization):\")\n",
    "print(df_clean['country'].value_counts().head(20))\n",
    "\n",
    "# Count how many US records we have\n",
    "us_count = (df_clean['country'] == 'US').sum()\n",
    "total_count = len(df_clean)\n",
    "us_percentage = (us_count / total_count) * 100\n",
    "\n",
    "print(f\"\\nüá∫üá∏ US Records: {us_count:,} ({us_percentage:.1f}% of dataset)\")\n",
    "print(f\"üåé Non-US Records: {total_count - us_count:,} ({100 - us_percentage:.1f}% of dataset)\")\n",
    "\n",
    "# ----------------\n",
    "# STATE CLEANING (US only)\n",
    "# ----------------\n",
    "print(\"\\n\\nüó∫Ô∏è  STATE CLEANING (US ONLY)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Filter to US records only for state analysis\n",
    "df_us = df_clean[df_clean['country'] == 'US'].copy()\n",
    "\n",
    "print(f\"\\nüìä Working with {len(df_us):,} US records\")\n",
    "\n",
    "# Check state data quality\n",
    "print(f\"\\nüìã State column info:\")\n",
    "print(f\"   Total US records: {len(df_us):,}\")\n",
    "print(f\"   Records with state data: {df_us['state'].notna().sum():,}\")\n",
    "print(f\"   Records missing state: {df_us['state'].isna().sum():,}\")\n",
    "print(f\"   Missing state percentage: {(df_us['state'].isna().sum() / len(df_us)) * 100:.1f}%\")\n",
    "\n",
    "# Check unique state values\n",
    "print(f\"\\nüìç Unique state values: {df_us['state'].nunique()}\")\n",
    "\n",
    "# Show top states\n",
    "print(\"\\nüìä Top 20 States (Before Cleaning):\")\n",
    "print(df_us['state'].value_counts().head(20))\n",
    "\n",
    "# Check for problematic state entries\n",
    "print(\"\\nüîç Checking for problematic state entries...\")\n",
    "\n",
    "# Find states that are too long (likely not abbreviations or proper names)\n",
    "long_states = df_us[df_us['state'].str.len() > 20]['state'].value_counts()\n",
    "if len(long_states) > 0:\n",
    "    print(f\"\\n   States with >20 characters ({len(long_states)} unique):\")\n",
    "    print(long_states.head(10))\n",
    "\n",
    "# Find states with multiple words (might be \"State, State\" or other issues)\n",
    "multi_word_states = df_us[df_us['state'].str.contains(',', na=False)]['state'].value_counts()\n",
    "if len(multi_word_states) > 0:\n",
    "    print(f\"\\n   States with commas ({len(multi_word_states)} unique):\")\n",
    "    print(multi_word_states.head(10))\n",
    "\n",
    "# Clean state data\n",
    "# Strip whitespace\n",
    "df_clean.loc[df_clean['country'] == 'US', 'state'] = df_clean.loc[df_clean['country'] == 'US', 'state'].str.strip()\n",
    "\n",
    "# Note: We're keeping state names as-is (both full names and abbreviations are acceptable)\n",
    "# This preserves data while removing obvious issues\n",
    "\n",
    "print(\"\\n‚úÖ State data cleaned (whitespace removed)\")\n",
    "\n",
    "# Final state statistics\n",
    "df_us_clean = df_clean[df_clean['country'] == 'US'].copy()\n",
    "print(\"\\nüìä Top 20 States (After Cleaning):\")\n",
    "print(df_us_clean['state'].value_counts().head(20))\n",
    "\n",
    "# Decision on missing states\n",
    "missing_state_count = df_us_clean['state'].isna().sum()\n",
    "print(f\"\\n‚ö†Ô∏è  Records with missing state data: {missing_state_count:,}\")\n",
    "print(\"   Decision: Keeping records with missing states for now.\")\n",
    "print(\"   Note: These will be excluded from state-specific analyses.\")\n",
    "\n",
    "print(\"\\n‚úÖ Phase 4 Complete!\")\n",
    "print(f\"‚ú® Cleaned dataset: {df_clean.shape[0]:,} rows √ó {df_clean.shape[1]} columns\")\n",
    "print(f\"   US records: {(df_clean['country'] == 'US').sum():,}\")\n",
    "print(f\"   US records with state: {df_clean[(df_clean['country'] == 'US') & (df_clean['state'].notna())].shape[0]:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PHASE 5: INDUSTRY & JOB TITLE CLEANING\n",
      "================================================================================\n",
      "\n",
      "üè¢ INDUSTRY ANALYSIS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìä Total unique industries: 350\n",
      "\n",
      "üìä Top 20 Industries:\n",
      "industry\n",
      "Computing or Tech                       1023\n",
      "Health care                              536\n",
      "Education (Higher Education)             506\n",
      "Nonprofits                               505\n",
      "Engineering or Manufacturing             472\n",
      "Accounting, Banking & Finance            437\n",
      "Government and Public Administration     317\n",
      "Marketing, Advertising & PR              267\n",
      "Law                                      245\n",
      "Business or Consulting                   211\n",
      "Education (Primary/Secondary)            176\n",
      "Media & Digital                          164\n",
      "Insurance                                129\n",
      "Recruitment or HR                        129\n",
      "Retail                                   128\n",
      "Sales                                     91\n",
      "Property or Construction                  90\n",
      "Transport or Logistics                    87\n",
      "Art & Design                              84\n",
      "Utilities & Telecommunications            78\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üíª Tech/Computing Industry Identification:\n",
      "   Industry name: 'Computing or Tech'\n",
      "   Tech industry records: 1,023\n",
      "\n",
      "\n",
      "üë®‚Äçüíª JOB TITLE ANALYSIS - SOFTWARE ENGINEERS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìã Top 30 Job Titles in Tech Industry:\n",
      "job_title\n",
      "Software Engineer                49\n",
      "Senior Software Engineer         37\n",
      "Product Manager                  20\n",
      "Engineering Manager              14\n",
      "Software Developer               12\n",
      "Project Manager                  12\n",
      "Data Analyst                     11\n",
      "Staff Software Engineer           9\n",
      "Software engineer                 9\n",
      "Program Manager                   9\n",
      "software engineer                 9\n",
      "Software Engineer II              8\n",
      "Customer Success Manager          7\n",
      "Technical Writer                  6\n",
      "Director of Engineering           6\n",
      "Data Scientist                    6\n",
      "Technical Program Manager         5\n",
      "IT Manager                        5\n",
      "Senior Director                   5\n",
      "Principal Software Engineer       5\n",
      "Senior software engineer          5\n",
      "Senior Project Manager            5\n",
      "Senior Data Scientist             5\n",
      "Sales Engineer                    5\n",
      "Lead Software Engineer            5\n",
      "Senior Product Manager            5\n",
      "Senior Software Developer         4\n",
      "Software Development Engineer     4\n",
      "Chief of Staff                    4\n",
      "Product Owner                     4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üîç Identifying Software Engineer variations...\n",
      "\n",
      "‚úÖ Software Engineer roles identified: 257\n",
      "\n",
      "üìã Sample of Matched Software Engineer Titles:\n",
      "job_title\n",
      "Software Engineer                59\n",
      "Senior Software Engineer         44\n",
      "Software Developer               13\n",
      "Staff Software Engineer          11\n",
      "Software engineer                11\n",
      "Software Engineer II              9\n",
      "software engineer                 9\n",
      "Principal Software Engineer       7\n",
      "Software engineer                 5\n",
      "Senior software engineer          5\n",
      "Lead Software Engineer            5\n",
      "Senior Software Developer         5\n",
      "Software Development Engineer     4\n",
      "Software Engineering Manager      4\n",
      "senior software engineer          3\n",
      "Software Engineer                 3\n",
      "Software Engineer III             2\n",
      "Senior software engineer          2\n",
      "Embedded Software Engineer        2\n",
      "Software Architect                2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "üö® DATA QUALITY - SUSPICIOUS ENTRY DETECTION\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üîç Checking for suspicious job titles...\n",
      "\n",
      "‚ö†Ô∏è  Suspicious entries found: 15\n",
      "\n",
      "üìã Sample of Suspicious Entries:\n",
      "                                    job_title    salary  \\\n",
      "20647                                      Na  100000.0   \n",
      "21079             Sr. Software Engineer, Test  121000.0   \n",
      "22410               Test automation engineer    85000.0   \n",
      "23083                           Test Engineer   88000.0   \n",
      "23684  Executive Director of Test Development   80000.0   \n",
      "23941                 Software test engineer    67000.0   \n",
      "24891                           Test Engineer  100000.0   \n",
      "25988                  Software Test Engineer   95000.0   \n",
      "26142            Test Development Coordinator   65000.0   \n",
      "27279                        Test Engineer IV  125000.0   \n",
      "27643                                 Student   18720.0   \n",
      "27663                Test Automation Engineer  125000.0   \n",
      "27664                Test Automation Engineer  125000.0   \n",
      "27974                                 student   35000.0   \n",
      "28047                                    test   20000.0   \n",
      "\n",
      "                            industry  \n",
      "20647              Computing or Tech  \n",
      "21079                Media & Digital  \n",
      "22410              Computing or Tech  \n",
      "23083   Engineering or Manufacturing  \n",
      "23684         Business or Consulting  \n",
      "23941              Computing or Tech  \n",
      "24891              Computing or Tech  \n",
      "25988              Computing or Tech  \n",
      "26142                     Nonprofits  \n",
      "27279   Engineering or Manufacturing  \n",
      "27643                        Student  \n",
      "27663   Engineering or Manufacturing  \n",
      "27664   Engineering or Manufacturing  \n",
      "27974   Education (Higher Education)  \n",
      "28047  Accounting, Banking & Finance  \n",
      "\n",
      "üí∞ Salary stats for suspicious entries:\n",
      "count        15.000000\n",
      "mean      83314.666667\n",
      "std       36331.247052\n",
      "min       18720.000000\n",
      "25%       66000.000000\n",
      "50%       88000.000000\n",
      "75%      110500.000000\n",
      "max      125000.000000\n",
      "Name: salary, dtype: float64\n",
      "\n",
      "üìè Job titles ‚â§ 2 characters: 26\n",
      "      job_title    salary                       industry\n",
      "20413        RN   85000.0                    Health care\n",
      "20639        VP  140000.0                     Nonprofits\n",
      "20647        Na  100000.0              Computing or Tech\n",
      "21147        RN   78000.0                    Health care\n",
      "21457        RN   50336.0                    Health care\n",
      "22129        RN   88400.0                    Health care\n",
      "22377        RN   67250.0                    Health care\n",
      "22933        Vp  160000.0  Accounting, Banking & Finance\n",
      "23531        VP   86228.0  Accounting, Banking & Finance\n",
      "23794        RN   90000.0                    Health care\n",
      "\n",
      "‚ùì Missing job titles: 0\n",
      "\n",
      "‚ö†Ô∏è  Suspicious entries found: 15\n",
      "\n",
      "üìã Sample of Suspicious Entries:\n",
      "                                    job_title    salary  \\\n",
      "20647                                      Na  100000.0   \n",
      "21079             Sr. Software Engineer, Test  121000.0   \n",
      "22410               Test automation engineer    85000.0   \n",
      "23083                           Test Engineer   88000.0   \n",
      "23684  Executive Director of Test Development   80000.0   \n",
      "23941                 Software test engineer    67000.0   \n",
      "24891                           Test Engineer  100000.0   \n",
      "25988                  Software Test Engineer   95000.0   \n",
      "26142            Test Development Coordinator   65000.0   \n",
      "27279                        Test Engineer IV  125000.0   \n",
      "27643                                 Student   18720.0   \n",
      "27663                Test Automation Engineer  125000.0   \n",
      "27664                Test Automation Engineer  125000.0   \n",
      "27974                                 student   35000.0   \n",
      "28047                                    test   20000.0   \n",
      "\n",
      "                            industry  \n",
      "20647              Computing or Tech  \n",
      "21079                Media & Digital  \n",
      "22410              Computing or Tech  \n",
      "23083   Engineering or Manufacturing  \n",
      "23684         Business or Consulting  \n",
      "23941              Computing or Tech  \n",
      "24891              Computing or Tech  \n",
      "25988              Computing or Tech  \n",
      "26142                     Nonprofits  \n",
      "27279   Engineering or Manufacturing  \n",
      "27643                        Student  \n",
      "27663   Engineering or Manufacturing  \n",
      "27664   Engineering or Manufacturing  \n",
      "27974   Education (Higher Education)  \n",
      "28047  Accounting, Banking & Finance  \n",
      "\n",
      "üí∞ Salary stats for suspicious entries:\n",
      "count        15.000000\n",
      "mean      83314.666667\n",
      "std       36331.247052\n",
      "min       18720.000000\n",
      "25%       66000.000000\n",
      "50%       88000.000000\n",
      "75%      110500.000000\n",
      "max      125000.000000\n",
      "Name: salary, dtype: float64\n",
      "\n",
      "üìè Job titles ‚â§ 2 characters: 26\n",
      "      job_title    salary                       industry\n",
      "20413        RN   85000.0                    Health care\n",
      "20639        VP  140000.0                     Nonprofits\n",
      "20647        Na  100000.0              Computing or Tech\n",
      "21147        RN   78000.0                    Health care\n",
      "21457        RN   50336.0                    Health care\n",
      "22129        RN   88400.0                    Health care\n",
      "22377        RN   67250.0                    Health care\n",
      "22933        Vp  160000.0  Accounting, Banking & Finance\n",
      "23531        VP   86228.0  Accounting, Banking & Finance\n",
      "23794        RN   90000.0                    Health care\n",
      "\n",
      "‚ùì Missing job titles: 0\n",
      "\n",
      "‚úÖ Removed suspicious job title entries\n",
      "   Rows removed: 15\n",
      "\n",
      "‚úÖ Removed very short job titles (‚â§2 chars)\n",
      "   Rows removed: 25\n",
      "\n",
      "\n",
      "üìä FINAL INDUSTRY SUMMARY\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üèÜ Top 15 Industries (After Cleaning):\n",
      "industry\n",
      "Computing or Tech                       1018\n",
      "Health care                              517\n",
      "Education (Higher Education)             505\n",
      "Nonprofits                               503\n",
      "Engineering or Manufacturing             468\n",
      "Accounting, Banking & Finance            433\n",
      "Government and Public Administration     317\n",
      "Marketing, Advertising & PR              267\n",
      "Law                                      245\n",
      "Business or Consulting                   209\n",
      "Education (Primary/Secondary)            176\n",
      "Media & Digital                          163\n",
      "Recruitment or HR                        129\n",
      "Insurance                                129\n",
      "Retail                                   128\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üíª Tech industry records: 1,018\n",
      "üë®‚Äçüíª Software Engineer roles: 249\n",
      "\n",
      "‚úÖ Phase 5 Complete!\n",
      "‚ú® Cleaned dataset: 6,405 rows √ó 14 columns\n",
      "\n",
      "‚úÖ Removed suspicious job title entries\n",
      "   Rows removed: 15\n",
      "\n",
      "‚úÖ Removed very short job titles (‚â§2 chars)\n",
      "   Rows removed: 25\n",
      "\n",
      "\n",
      "üìä FINAL INDUSTRY SUMMARY\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üèÜ Top 15 Industries (After Cleaning):\n",
      "industry\n",
      "Computing or Tech                       1018\n",
      "Health care                              517\n",
      "Education (Higher Education)             505\n",
      "Nonprofits                               503\n",
      "Engineering or Manufacturing             468\n",
      "Accounting, Banking & Finance            433\n",
      "Government and Public Administration     317\n",
      "Marketing, Advertising & PR              267\n",
      "Law                                      245\n",
      "Business or Consulting                   209\n",
      "Education (Primary/Secondary)            176\n",
      "Media & Digital                          163\n",
      "Recruitment or HR                        129\n",
      "Insurance                                129\n",
      "Retail                                   128\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üíª Tech industry records: 1,018\n",
      "üë®‚Äçüíª Software Engineer roles: 249\n",
      "\n",
      "‚úÖ Phase 5 Complete!\n",
      "‚ú® Cleaned dataset: 6,405 rows √ó 14 columns\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# PHASE 5: Industry & Job Title Cleaning\n",
    "# ============================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"PHASE 5: INDUSTRY & JOB TITLE CLEANING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ----------------\n",
    "# INDUSTRY ANALYSIS\n",
    "# ----------------\n",
    "print(\"\\nüè¢ INDUSTRY ANALYSIS\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Check unique industries\n",
    "print(f\"\\nüìä Total unique industries: {df_clean['industry'].nunique()}\")\n",
    "\n",
    "# Show top industries\n",
    "print(\"\\nüìä Top 20 Industries:\")\n",
    "print(df_clean['industry'].value_counts().head(20))\n",
    "\n",
    "# Identify the tech/computing industry value\n",
    "print(\"\\nüíª Tech/Computing Industry Identification:\")\n",
    "tech_industry_value = 'Computing or Tech'\n",
    "tech_count = (df_clean['industry'] == tech_industry_value).sum()\n",
    "print(f\"   Industry name: '{tech_industry_value}'\")\n",
    "print(f\"   Tech industry records: {tech_count:,}\")\n",
    "\n",
    "# ----------------\n",
    "# JOB TITLE ANALYSIS FOR SOFTWARE ENGINEERS\n",
    "# ----------------\n",
    "print(\"\\n\\nüë®‚Äçüíª JOB TITLE ANALYSIS - SOFTWARE ENGINEERS\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# First, let's see what job titles exist in tech industry\n",
    "tech_jobs = df_clean[df_clean['industry'] == tech_industry_value]['job_title'].value_counts().head(30)\n",
    "print(\"\\nüìã Top 30 Job Titles in Tech Industry:\")\n",
    "print(tech_jobs)\n",
    "\n",
    "# Create a flag for Software Engineer roles using flexible matching\n",
    "# Strategy: Look for variations of \"software\" AND \"engineer/developer\"\n",
    "print(\"\\nüîç Identifying Software Engineer variations...\")\n",
    "\n",
    "# Convert job titles to lowercase for case-insensitive matching\n",
    "df_clean['job_title_lower'] = df_clean['job_title'].str.lower().str.strip()\n",
    "\n",
    "# Define patterns for Software Engineer identification\n",
    "# Pattern 1: Contains \"software\" AND (\"engineer\" OR \"developer\" OR \"dev\")\n",
    "is_swe = (\n",
    "    (df_clean['job_title_lower'].str.contains('software', na=False)) &\n",
    "    (\n",
    "        df_clean['job_title_lower'].str.contains('engineer', na=False) |\n",
    "        df_clean['job_title_lower'].str.contains('developer', na=False) |\n",
    "        df_clean['job_title_lower'].str.contains(r'\\bdev\\b', na=False, regex=True)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Pattern 2: Common abbreviations\n",
    "is_swe = is_swe | df_clean['job_title_lower'].str.contains(r'\\bswe\\b', na=False, regex=True)\n",
    "\n",
    "# Pattern 3: \"Software\" alone (like \"Software Developer\", \"Software Architect\")\n",
    "is_swe = is_swe | (\n",
    "    df_clean['job_title_lower'].str.contains('software', na=False) &\n",
    "    df_clean['job_title_lower'].str.contains('developer|dev |engineer|architect|programmer', na=False, regex=True)\n",
    ")\n",
    "\n",
    "df_clean['is_software_engineer'] = is_swe\n",
    "\n",
    "swe_count = df_clean['is_software_engineer'].sum()\n",
    "print(f\"\\n‚úÖ Software Engineer roles identified: {swe_count:,}\")\n",
    "\n",
    "# Show sample of matched titles\n",
    "print(\"\\nüìã Sample of Matched Software Engineer Titles:\")\n",
    "swe_sample_titles = df_clean[df_clean['is_software_engineer']]['job_title'].value_counts().head(20)\n",
    "print(swe_sample_titles)\n",
    "\n",
    "# ----------------\n",
    "# DATA QUALITY - SUSPICIOUS ENTRIES\n",
    "# ----------------\n",
    "print(\"\\n\\nüö® DATA QUALITY - SUSPICIOUS ENTRY DETECTION\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Define suspicious job title keywords (using word boundaries to avoid false positives)\n",
    "# Pattern explanation: \\b ensures we match complete words only, not substrings\n",
    "suspicious_patterns = [\n",
    "    r'\\bbum\\b',           # \"bum\" but not \"bumblebee\"\n",
    "    r'\\bunemployed\\b',    # \"unemployed\" \n",
    "    r'^student$',         # ONLY if the entire title is just \"student\"\n",
    "    r'\\bnone\\b',          # \"none\" but not \"nonetheless\"\n",
    "    r'\\bn/a\\b',           # \"n/a\"\n",
    "    r'^na$',              # ONLY if the entire title is just \"na\"\n",
    "    r'\\btest\\b',          # \"test\" but not \"testing\" or \"contest\"\n",
    "    r'\\basdf\\b',          # gibberish\n",
    "    r'\\bretired\\b',       # \"retired\"\n",
    "    r'\\bhomemaker\\b',     # \"homemaker\"\n",
    "    r'\\bstay at home\\b',  # \"stay at home\"\n",
    "    r'\\bsahm\\b',          # \"sahm\"\n",
    "    r'\\bxxx\\b',           # profanity marker\n",
    "    r'\\bfuck',            # profanity\n",
    "    r'\\bshit',            # profanity\n",
    "    r'\\bcrap\\b',          # profanity\n",
    "    r'\\bidiot\\b',         # insult\n",
    "    r'\\bstupid\\b',        # insult\n",
    "    r'^nothing$',         # ONLY if entire title is \"nothing\"\n",
    "    r'\\bno job\\b',        # \"no job\"\n",
    "    r'\\bnojob\\b',         # \"nojob\"\n",
    "    r'\\bseeking\\b',       # \"seeking\" (job seeker)\n",
    "    r'\\blooking for work\\b',  # \"looking for work\"\n",
    "    r'\\bjob seeker\\b',    # \"job seeker\"\n",
    "    r'\\bbetween jobs\\b'   # \"between jobs\"\n",
    "]\n",
    "\n",
    "# Check for suspicious entries (case-insensitive)\n",
    "print(\"\\nüîç Checking for suspicious job titles...\")\n",
    "\n",
    "# Combine all patterns with OR (|)\n",
    "suspicious_regex = '|'.join(suspicious_patterns)\n",
    "suspicious_mask = df_clean['job_title_lower'].str.contains(suspicious_regex, na=False, regex=True)\n",
    "suspicious_entries = df_clean[suspicious_mask]\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è  Suspicious entries found: {len(suspicious_entries):,}\")\n",
    "\n",
    "if len(suspicious_entries) > 0:\n",
    "    print(\"\\nüìã Sample of Suspicious Entries:\")\n",
    "    print(suspicious_entries[['job_title', 'salary', 'industry']].head(20))\n",
    "    \n",
    "    # Show salary stats for suspicious entries\n",
    "    print(\"\\nüí∞ Salary stats for suspicious entries:\")\n",
    "    print(suspicious_entries['salary'].describe())\n",
    "\n",
    "# Check for very short job titles (likely gibberish or incomplete)\n",
    "short_titles = df_clean[df_clean['job_title'].str.len() <= 2]\n",
    "print(f\"\\nüìè Job titles ‚â§ 2 characters: {len(short_titles):,}\")\n",
    "if len(short_titles) > 0:\n",
    "    print(short_titles[['job_title', 'salary', 'industry']].head(10))\n",
    "\n",
    "# Check for missing job titles\n",
    "missing_titles = df_clean['job_title'].isna().sum()\n",
    "print(f\"\\n‚ùì Missing job titles: {missing_titles:,}\")\n",
    "\n",
    "# Decision: Remove suspicious entries\n",
    "rows_before_suspicious = len(df_clean)\n",
    "df_clean = df_clean[~suspicious_mask].copy()\n",
    "rows_after_suspicious = len(df_clean)\n",
    "rows_removed_suspicious = rows_before_suspicious - rows_after_suspicious\n",
    "\n",
    "print(f\"\\n‚úÖ Removed suspicious job title entries\")\n",
    "print(f\"   Rows removed: {rows_removed_suspicious:,}\")\n",
    "\n",
    "# Remove very short titles (likely invalid)\n",
    "if len(short_titles) > 0:\n",
    "    rows_before_short = len(df_clean)\n",
    "    df_clean = df_clean[df_clean['job_title'].str.len() > 2].copy()\n",
    "    rows_removed_short = rows_before_short - len(df_clean)\n",
    "    print(f\"\\n‚úÖ Removed very short job titles (‚â§2 chars)\")\n",
    "    print(f\"   Rows removed: {rows_removed_short:,}\")\n",
    "\n",
    "# Remove missing job titles\n",
    "if missing_titles > 0:\n",
    "    rows_before_missing = len(df_clean)\n",
    "    df_clean = df_clean[df_clean['job_title'].notna()].copy()\n",
    "    rows_removed_missing = rows_before_missing - len(df_clean)\n",
    "    print(f\"\\n‚úÖ Removed missing job titles\")\n",
    "    print(f\"   Rows removed: {rows_removed_missing:,}\")\n",
    "\n",
    "# Update the is_software_engineer flag after cleaning\n",
    "df_clean['job_title_lower'] = df_clean['job_title'].str.lower().str.strip()\n",
    "is_swe = (\n",
    "    (df_clean['job_title_lower'].str.contains('software', na=False)) &\n",
    "    (\n",
    "        df_clean['job_title_lower'].str.contains('engineer', na=False) |\n",
    "        df_clean['job_title_lower'].str.contains('developer', na=False) |\n",
    "        df_clean['job_title_lower'].str.contains(r'\\bdev\\b', na=False, regex=True)\n",
    "    )\n",
    ")\n",
    "is_swe = is_swe | df_clean['job_title_lower'].str.contains(r'\\bswe\\b', na=False, regex=True)\n",
    "df_clean['is_software_engineer'] = is_swe\n",
    "\n",
    "# ----------------\n",
    "# FINAL INDUSTRY SUMMARY\n",
    "# ----------------\n",
    "print(\"\\n\\nüìä FINAL INDUSTRY SUMMARY\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(\"\\nüèÜ Top 15 Industries (After Cleaning):\")\n",
    "print(df_clean['industry'].value_counts().head(15))\n",
    "\n",
    "tech_count_final = (df_clean['industry'] == tech_industry_value).sum()\n",
    "swe_count_final = df_clean['is_software_engineer'].sum()\n",
    "\n",
    "print(f\"\\nüíª Tech industry records: {tech_count_final:,}\")\n",
    "print(f\"üë®‚Äçüíª Software Engineer roles: {swe_count_final:,}\")\n",
    "\n",
    "print(\"\\n‚úÖ Phase 5 Complete!\")\n",
    "print(f\"‚ú® Cleaned dataset: {df_clean.shape[0]:,} rows √ó {df_clean.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PHASE 6: EXPERIENCE & EDUCATION CLEANING\n",
      "================================================================================\n",
      "\n",
      "üìÖ YEARS OF EXPERIENCE ANALYSIS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìä Unique values in 'years_experience_field':\n",
      "years_experience_field\n",
      "1 year or less       430\n",
      "11 - 20 years       1453\n",
      "2 - 4 years         1396\n",
      "21 - 30 years        389\n",
      "31 - 40 years         67\n",
      "41 years or more       5\n",
      "5-7 years           1503\n",
      "8 - 10 years        1162\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üìä Unique values in 'years_experience_overall':\n",
      "years_experience_overall\n",
      "1 year or less       139\n",
      "11 - 20 years       2228\n",
      "2 - 4 years          757\n",
      "21 - 30 years        762\n",
      "31 - 40 years        183\n",
      "41 years or more      24\n",
      "5-7 years           1115\n",
      "8 - 10 years        1197\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üîÑ Converting experience ranges to numeric values...\n",
      "\n",
      "‚úÖ Experience converted to numeric!\n",
      "\n",
      "üìä Field Experience Statistics:\n",
      "count    6405.000000\n",
      "mean        9.230055\n",
      "std         6.962347\n",
      "min         1.000000\n",
      "25%         3.000000\n",
      "50%         6.000000\n",
      "75%        15.500000\n",
      "max        41.000000\n",
      "Name: years_experience_field_num, dtype: float64\n",
      "\n",
      "üìä Overall Experience Statistics:\n",
      "count    6405.000000\n",
      "mean       12.696097\n",
      "std         8.034112\n",
      "min         1.000000\n",
      "25%         6.000000\n",
      "50%         9.000000\n",
      "75%        15.500000\n",
      "max        41.000000\n",
      "Name: years_experience_overall_num, dtype: float64\n",
      "\n",
      "‚ùì Missing field experience: 0 (0.0%)\n",
      "‚ùì Missing overall experience: 0 (0.0%)\n",
      "\n",
      "üìã Sample Conversions (Field Experience):\n",
      "years_experience_field  years_experience_field_num\n",
      "           2 - 4 years                         3.0\n",
      "         11 - 20 years                        15.5\n",
      "             5-7 years                         6.0\n",
      "         21 - 30 years                        25.5\n",
      "        1 year or less                         1.0\n",
      "          8 - 10 years                         9.0\n",
      "         31 - 40 years                        35.5\n",
      "      41 years or more                        41.0\n",
      "\n",
      "\n",
      "üéì EDUCATION LEVEL ANALYSIS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìä Education Levels Distribution:\n",
      "education\n",
      "College degree                        3167\n",
      "Master's degree                       2001\n",
      "Some college                           500\n",
      "Professional degree (MD, JD, etc.)     295\n",
      "PhD                                    268\n",
      "High School                            132\n",
      "Name: count, dtype: int64\n",
      "\n",
      "‚ùì Missing education: 42 (0.7%)\n",
      "\n",
      "üîÑ Standardizing education levels...\n",
      "\n",
      "‚úÖ Education standardized!\n",
      "\n",
      "üìä Standardized Education Distribution:\n",
      "education_standard\n",
      "College degree         3667\n",
      "Master's degree        2001\n",
      "Professional degree     295\n",
      "PhD                     268\n",
      "High School             132\n",
      "Unknown                  42\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üéì Education Breakdown:\n",
      "   College/Bachelor's degree: 3,667\n",
      "   Master's degree: 2,001\n",
      "   PhD: 268\n",
      "\n",
      "‚úÖ Education level numeric scale created (1-6)\n",
      "\n",
      "üí∞ Average Salary by Education Level:\n",
      "                     count           mean    median\n",
      "education_standard                                 \n",
      "Professional degree    295  141401.315254  125000.0\n",
      "PhD                    268  110324.182836  100000.0\n",
      "Master's degree       2001   94061.554723   85000.0\n",
      "Unknown                 42  101281.309524   74500.0\n",
      "College degree        3667   85938.189801   73500.0\n",
      "High School            132   69861.674242   49481.5\n",
      "\n",
      "‚úÖ Phase 6 Complete!\n",
      "‚ú® Cleaned dataset: 6,405 rows √ó 21 columns\n",
      "\n",
      "üìä New columns added:\n",
      "   - years_experience_field_num (numeric)\n",
      "   - years_experience_overall_num (numeric)\n",
      "   - education_standard (standardized categories)\n",
      "   - education_level (numeric 1-6)\n",
      "   - has_bachelors, has_masters, has_phd (boolean flags)\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# PHASE 6: Experience & Education Cleaning\n",
    "# ============================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"PHASE 6: EXPERIENCE & EDUCATION CLEANING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ----------------\n",
    "# YEARS OF EXPERIENCE CLEANING\n",
    "# ----------------\n",
    "print(\"\\nüìÖ YEARS OF EXPERIENCE ANALYSIS\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Check current experience values\n",
    "print(\"\\nüìä Unique values in 'years_experience_field':\")\n",
    "print(df_clean['years_experience_field'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\nüìä Unique values in 'years_experience_overall':\")\n",
    "print(df_clean['years_experience_overall'].value_counts().sort_index())\n",
    "\n",
    "# Function to convert experience text ranges to numeric midpoint\n",
    "def convert_experience_to_numeric(exp_text):\n",
    "    \"\"\"\n",
    "    Convert experience text ranges to numeric values.\n",
    "    Examples:\n",
    "      '5-7 years' -> 6\n",
    "      '8 - 10 years' -> 9\n",
    "      '1 year or less' -> 1\n",
    "      '21 - 30 years' -> 25.5\n",
    "      '41 years or more' -> 41\n",
    "    \"\"\"\n",
    "    if pd.isna(exp_text):\n",
    "        return np.nan\n",
    "    \n",
    "    exp_text = str(exp_text).strip().lower()\n",
    "    \n",
    "    # Handle '1 year or less'\n",
    "    if '1 year or less' in exp_text or exp_text == '1':\n",
    "        return 1.0\n",
    "    \n",
    "    # Handle '41 years or more' or similar\n",
    "    if 'or more' in exp_text or '41 years' in exp_text:\n",
    "        return 41.0\n",
    "    \n",
    "    # Extract numbers from ranges like '5-7 years', '8 - 10 years', '2 - 4 years'\n",
    "    import re\n",
    "    numbers = re.findall(r'\\d+', exp_text)\n",
    "    \n",
    "    if len(numbers) == 2:\n",
    "        # Range like '5-7' -> take midpoint\n",
    "        return (int(numbers[0]) + int(numbers[1])) / 2\n",
    "    elif len(numbers) == 1:\n",
    "        # Single number\n",
    "        return float(numbers[0])\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# Apply conversion to both experience columns\n",
    "print(\"\\nüîÑ Converting experience ranges to numeric values...\")\n",
    "\n",
    "df_clean['years_experience_field_num'] = df_clean['years_experience_field'].apply(convert_experience_to_numeric)\n",
    "df_clean['years_experience_overall_num'] = df_clean['years_experience_overall'].apply(convert_experience_to_numeric)\n",
    "\n",
    "# Show conversion results\n",
    "print(\"\\n‚úÖ Experience converted to numeric!\")\n",
    "print(\"\\nüìä Field Experience Statistics:\")\n",
    "print(df_clean['years_experience_field_num'].describe())\n",
    "\n",
    "print(\"\\nüìä Overall Experience Statistics:\")\n",
    "print(df_clean['years_experience_overall_num'].describe())\n",
    "\n",
    "# Check for missing values\n",
    "field_exp_missing = df_clean['years_experience_field_num'].isna().sum()\n",
    "overall_exp_missing = df_clean['years_experience_overall_num'].isna().sum()\n",
    "\n",
    "print(f\"\\n‚ùì Missing field experience: {field_exp_missing:,} ({(field_exp_missing/len(df_clean))*100:.1f}%)\")\n",
    "print(f\"‚ùì Missing overall experience: {overall_exp_missing:,} ({(overall_exp_missing/len(df_clean))*100:.1f}%)\")\n",
    "\n",
    "# Show sample of conversions\n",
    "print(\"\\nüìã Sample Conversions (Field Experience):\")\n",
    "sample_df = df_clean[['years_experience_field', 'years_experience_field_num']].drop_duplicates().head(15)\n",
    "print(sample_df.to_string(index=False))\n",
    "\n",
    "# ----------------\n",
    "# EDUCATION CLEANING\n",
    "# ----------------\n",
    "print(\"\\n\\nüéì EDUCATION LEVEL ANALYSIS\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Check current education values\n",
    "print(\"\\nüìä Education Levels Distribution:\")\n",
    "print(df_clean['education'].value_counts())\n",
    "\n",
    "# Check for missing education\n",
    "education_missing = df_clean['education'].isna().sum()\n",
    "print(f\"\\n‚ùì Missing education: {education_missing:,} ({(education_missing/len(df_clean))*100:.1f}%)\")\n",
    "\n",
    "# Standardize education levels\n",
    "print(\"\\nüîÑ Standardizing education levels...\")\n",
    "\n",
    "# Create standardized education categories\n",
    "def standardize_education(edu_text):\n",
    "    \"\"\"\n",
    "    Standardize education levels into consistent categories.\n",
    "    \"\"\"\n",
    "    if pd.isna(edu_text):\n",
    "        return 'Unknown'\n",
    "    \n",
    "    edu_text = str(edu_text).strip().lower()\n",
    "    \n",
    "    # PhD\n",
    "    if 'phd' in edu_text or 'doctorate' in edu_text:\n",
    "        return 'PhD'\n",
    "    \n",
    "    # Master's degree\n",
    "    if 'master' in edu_text:\n",
    "        return \"Master's degree\"\n",
    "    \n",
    "    # College/Bachelor's degree\n",
    "    if 'college' in edu_text or 'bachelor' in edu_text:\n",
    "        return \"College degree\"\n",
    "    \n",
    "    # Professional degree (JD, MD, etc.)\n",
    "    if 'professional' in edu_text:\n",
    "        return 'Professional degree'\n",
    "    \n",
    "    # Some college\n",
    "    if 'some college' in edu_text:\n",
    "        return 'Some college'\n",
    "    \n",
    "    # High school\n",
    "    if 'high school' in edu_text:\n",
    "        return 'High School'\n",
    "    \n",
    "    # Default\n",
    "    return 'Other'\n",
    "\n",
    "df_clean['education_standard'] = df_clean['education'].apply(standardize_education)\n",
    "\n",
    "print(\"\\n‚úÖ Education standardized!\")\n",
    "print(\"\\nüìä Standardized Education Distribution:\")\n",
    "print(df_clean['education_standard'].value_counts())\n",
    "\n",
    "# Create Bachelor's vs Master's comparison groups\n",
    "df_clean['has_bachelors'] = df_clean['education_standard'] == 'College degree'\n",
    "df_clean['has_masters'] = df_clean['education_standard'] == \"Master's degree\"\n",
    "df_clean['has_phd'] = df_clean['education_standard'] == 'PhD'\n",
    "\n",
    "bachelors_count = df_clean['has_bachelors'].sum()\n",
    "masters_count = df_clean['has_masters'].sum()\n",
    "phd_count = df_clean['has_phd'].sum()\n",
    "\n",
    "print(f\"\\nüéì Education Breakdown:\")\n",
    "print(f\"   College/Bachelor's degree: {bachelors_count:,}\")\n",
    "print(f\"   Master's degree: {masters_count:,}\")\n",
    "print(f\"   PhD: {phd_count:,}\")\n",
    "\n",
    "# Create education level ordering for analysis\n",
    "education_order = {\n",
    "    'High School': 1,\n",
    "    'Some college': 2,\n",
    "    'College degree': 3,\n",
    "    \"Master's degree\": 4,\n",
    "    'Professional degree': 5,\n",
    "    'PhD': 6,\n",
    "    'Other': 0,\n",
    "    'Unknown': 0\n",
    "}\n",
    "\n",
    "df_clean['education_level'] = df_clean['education_standard'].map(education_order)\n",
    "\n",
    "print(\"\\n‚úÖ Education level numeric scale created (1-6)\")\n",
    "\n",
    "# Show education vs salary preview (for validation)\n",
    "print(\"\\nüí∞ Average Salary by Education Level:\")\n",
    "salary_by_edu = df_clean.groupby('education_standard')['salary'].agg(['count', 'mean', 'median']).sort_values('median', ascending=False)\n",
    "print(salary_by_edu)\n",
    "\n",
    "print(\"\\n‚úÖ Phase 6 Complete!\")\n",
    "print(f\"‚ú® Cleaned dataset: {df_clean.shape[0]:,} rows √ó {df_clean.shape[1]} columns\")\n",
    "print(f\"\\nüìä New columns added:\")\n",
    "print(f\"   - years_experience_field_num (numeric)\")\n",
    "print(f\"   - years_experience_overall_num (numeric)\")\n",
    "print(f\"   - education_standard (standardized categories)\")\n",
    "print(f\"   - education_level (numeric 1-6)\")\n",
    "print(f\"   - has_bachelors, has_masters, has_phd (boolean flags)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PHASE 7: GENDER DATA CLEANING\n",
      "================================================================================\n",
      "\n",
      "‚ößÔ∏è GENDER DATA ANALYSIS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìä Current Gender Distribution:\n",
      "gender\n",
      "Woman                            4818\n",
      "Man                              1339\n",
      "Non-binary                        136\n",
      "Other or prefer not to answer      66\n",
      "Name: count, dtype: int64\n",
      "\n",
      "‚ùì Missing gender: 46 (0.7%)\n",
      "\n",
      "üìç Unique gender values: 4\n",
      "\n",
      "üìã All unique gender values:\n",
      "   'Man': 1,339\n",
      "   'Non-binary': 136\n",
      "   'Other or prefer not to answer': 66\n",
      "   'Woman': 4,818\n",
      "\n",
      "\n",
      "üîÑ STANDARDIZING GENDER VALUES\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "‚úÖ Gender values standardized!\n",
      "\n",
      "üìä Standardized Gender Distribution:\n",
      "gender_standard\n",
      "Woman                         4818\n",
      "Man                           1339\n",
      "Non-binary                     136\n",
      "Other/Prefer not to answer      66\n",
      "Unknown                         46\n",
      "Name: count, dtype: int64\n",
      "\n",
      "‚ößÔ∏è Gender Breakdown:\n",
      "   Men: 1,339 (20.9%)\n",
      "   Women: 4,818 (75.2%)\n",
      "   Non-binary: 136 (2.1%)\n",
      "   Other/Prefer not to answer: 66 (1.0%)\n",
      "\n",
      "\n",
      "üìä GENDER PAY GAP ANALYSIS APPROACH\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üí° Decision for Pay Gap Analysis:\n",
      "   For binary gender pay gap comparison (Man vs Woman):\n",
      "   - We will use only 'Man' and 'Woman' categories\n",
      "   - Non-binary and Other categories will be excluded from binary comparison\n",
      "   - This ensures clear, statistically valid comparison\n",
      "   - Non-binary workers can be analyzed separately if needed\n",
      "\n",
      "üí∞ Average Salary by Gender (Preview):\n",
      "                            count           mean   median\n",
      "gender_standard                                          \n",
      "Man                          1339  108385.316654  95000.0\n",
      "Unknown                        46   96467.608696  87500.0\n",
      "Woman                        4818   87791.638439  76500.0\n",
      "Other/Prefer not to answer     66   85056.303030  72575.0\n",
      "Non-binary                    136   73154.845588  60000.0\n",
      "\n",
      "üìä Sample size for binary pay gap analysis:\n",
      "   Total records with Man/Woman gender: 6,157\n",
      "   Men: 1,339\n",
      "   Women: 4,818\n",
      "   Sample size is sufficient for statistical analysis\n",
      "\n",
      "üíª Tech Industry Gender Breakdown:\n",
      "                            count           mean    median\n",
      "gender_standard                                           \n",
      "Man                           428  137360.721963  131000.0\n",
      "Non-binary                     26  119517.692308   95750.0\n",
      "Other/Prefer not to answer      8  122625.000000  118500.0\n",
      "Unknown                         4  116750.000000  122500.0\n",
      "Woman                         552  119867.487319  113000.0\n",
      "\n",
      "‚úÖ Phase 7 Complete!\n",
      "‚ú® Cleaned dataset: 6,405 rows √ó 25 columns\n",
      "\n",
      "üìä New columns added:\n",
      "   - gender_standard (standardized categories)\n",
      "   - is_man, is_woman, is_nonbinary (boolean flags)\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# PHASE 7: Gender Data Cleaning\n",
    "# ============================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"PHASE 7: GENDER DATA CLEANING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ----------------\n",
    "# GENDER ANALYSIS\n",
    "# ----------------\n",
    "print(\"\\n‚ößÔ∏è GENDER DATA ANALYSIS\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Check current gender values\n",
    "print(\"\\nüìä Current Gender Distribution:\")\n",
    "print(df_clean['gender'].value_counts())\n",
    "\n",
    "# Check for missing gender\n",
    "gender_missing = df_clean['gender'].isna().sum()\n",
    "print(f\"\\n‚ùì Missing gender: {gender_missing:,} ({(gender_missing/len(df_clean))*100:.1f}%)\")\n",
    "\n",
    "# Show unique gender values\n",
    "print(f\"\\nüìç Unique gender values: {df_clean['gender'].nunique()}\")\n",
    "print(\"\\nüìã All unique gender values:\")\n",
    "for val in sorted(df_clean['gender'].dropna().unique()):\n",
    "    count = (df_clean['gender'] == val).sum()\n",
    "    print(f\"   '{val}': {count:,}\")\n",
    "\n",
    "# ----------------\n",
    "# STANDARDIZE GENDER VALUES\n",
    "# ----------------\n",
    "print(\"\\n\\nüîÑ STANDARDIZING GENDER VALUES\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Create standardized gender categories\n",
    "def standardize_gender(gender_text):\n",
    "    \"\"\"\n",
    "    Standardize gender values into consistent categories.\n",
    "    \"\"\"\n",
    "    if pd.isna(gender_text):\n",
    "        return 'Unknown'\n",
    "    \n",
    "    gender_text = str(gender_text).strip().lower()\n",
    "    \n",
    "    # Man/Male\n",
    "    if gender_text in ['man', 'male', 'm']:\n",
    "        return 'Man'\n",
    "    \n",
    "    # Woman/Female\n",
    "    if gender_text in ['woman', 'female', 'f']:\n",
    "        return 'Woman'\n",
    "    \n",
    "    # Non-binary\n",
    "    if 'non-binary' in gender_text or 'nonbinary' in gender_text or 'non binary' in gender_text:\n",
    "        return 'Non-binary'\n",
    "    \n",
    "    # Prefer not to answer / Other\n",
    "    if 'prefer not' in gender_text or 'other' in gender_text or 'another option' in gender_text:\n",
    "        return 'Other/Prefer not to answer'\n",
    "    \n",
    "    # Default - catch any other variations\n",
    "    return 'Other/Prefer not to answer'\n",
    "\n",
    "df_clean['gender_standard'] = df_clean['gender'].apply(standardize_gender)\n",
    "\n",
    "print(\"\\n‚úÖ Gender values standardized!\")\n",
    "print(\"\\nüìä Standardized Gender Distribution:\")\n",
    "print(df_clean['gender_standard'].value_counts())\n",
    "\n",
    "# Create flags for binary gender analysis\n",
    "df_clean['is_man'] = df_clean['gender_standard'] == 'Man'\n",
    "df_clean['is_woman'] = df_clean['gender_standard'] == 'Woman'\n",
    "df_clean['is_nonbinary'] = df_clean['gender_standard'] == 'Non-binary'\n",
    "\n",
    "man_count = df_clean['is_man'].sum()\n",
    "woman_count = df_clean['is_woman'].sum()\n",
    "nonbinary_count = df_clean['is_nonbinary'].sum()\n",
    "other_count = (df_clean['gender_standard'] == 'Other/Prefer not to answer').sum()\n",
    "\n",
    "print(f\"\\n‚ößÔ∏è Gender Breakdown:\")\n",
    "print(f\"   Men: {man_count:,} ({(man_count/len(df_clean))*100:.1f}%)\")\n",
    "print(f\"   Women: {woman_count:,} ({(woman_count/len(df_clean))*100:.1f}%)\")\n",
    "print(f\"   Non-binary: {nonbinary_count:,} ({(nonbinary_count/len(df_clean))*100:.1f}%)\")\n",
    "print(f\"   Other/Prefer not to answer: {other_count:,} ({(other_count/len(df_clean))*100:.1f}%)\")\n",
    "\n",
    "# ----------------\n",
    "# GENDER PAY GAP ANALYSIS DECISION\n",
    "# ----------------\n",
    "print(\"\\n\\nüìä GENDER PAY GAP ANALYSIS APPROACH\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(\"\\nüí° Decision for Pay Gap Analysis:\")\n",
    "print(\"   For binary gender pay gap comparison (Man vs Woman):\")\n",
    "print(\"   - We will use only 'Man' and 'Woman' categories\")\n",
    "print(\"   - Non-binary and Other categories will be excluded from binary comparison\")\n",
    "print(\"   - This ensures clear, statistically valid comparison\")\n",
    "print(\"   - Non-binary workers can be analyzed separately if needed\")\n",
    "\n",
    "# Show salary preview by gender\n",
    "print(\"\\nüí∞ Average Salary by Gender (Preview):\")\n",
    "salary_by_gender = df_clean.groupby('gender_standard')['salary'].agg(['count', 'mean', 'median']).sort_values('median', ascending=False)\n",
    "print(salary_by_gender)\n",
    "\n",
    "# Calculate sample sizes for pay gap analysis\n",
    "binary_gender_sample = df_clean[df_clean['gender_standard'].isin(['Man', 'Woman'])]\n",
    "print(f\"\\nüìä Sample size for binary pay gap analysis:\")\n",
    "print(f\"   Total records with Man/Woman gender: {len(binary_gender_sample):,}\")\n",
    "print(f\"   Men: {(binary_gender_sample['gender_standard'] == 'Man').sum():,}\")\n",
    "print(f\"   Women: {(binary_gender_sample['gender_standard'] == 'Woman').sum():,}\")\n",
    "print(f\"   Sample size is {'sufficient' if len(binary_gender_sample) > 1000 else 'limited'} for statistical analysis\")\n",
    "\n",
    "# Show tech-specific gender breakdown\n",
    "tech_gender = df_clean[df_clean['industry'] == 'Computing or Tech'].groupby('gender_standard')['salary'].agg(['count', 'mean', 'median'])\n",
    "print(\"\\nüíª Tech Industry Gender Breakdown:\")\n",
    "print(tech_gender)\n",
    "\n",
    "print(\"\\n‚úÖ Phase 7 Complete!\")\n",
    "print(f\"‚ú® Cleaned dataset: {df_clean.shape[0]:,} rows √ó {df_clean.shape[1]} columns\")\n",
    "print(f\"\\nüìä New columns added:\")\n",
    "print(f\"   - gender_standard (standardized categories)\")\n",
    "print(f\"   - is_man, is_woman, is_nonbinary (boolean flags)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PHASE 8: DATE/TIMESTAMP FILTERING\n",
      "================================================================================\n",
      "\n",
      "üìÖ TIMESTAMP ANALYSIS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìã Sample timestamp values:\n",
      "['4/29/2021 13:59:35', '4/29/2021 13:59:41', '4/29/2021 14:00:09', '4/29/2021 14:00:36', '4/29/2021 14:01:36', '4/29/2021 14:02:38', '4/29/2021 14:03:16', '4/29/2021 14:04:07', '4/29/2021 14:05:03', '4/29/2021 14:05:22']\n",
      "\n",
      "üìä Timestamp column type: object\n",
      "\n",
      "üîÑ Converting timestamp to datetime...\n",
      "   Conversion failures: 0\n",
      "\n",
      "‚úÖ Timestamp converted to datetime!\n",
      "\n",
      "\n",
      "üìä DATE RANGE ANALYSIS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìÖ Survey Date Range:\n",
      "   Earliest response: 2021-04-29 13:59:35\n",
      "   Latest response: 2024-07-23 17:51:03\n",
      "   Duration: 1181 days\n",
      "\n",
      "üìä Responses by Year:\n",
      "year\n",
      "2021    6071\n",
      "2022     248\n",
      "2023      53\n",
      "2024      33\n",
      "Name: count, dtype: int64\n",
      "\n",
      "‚úÖ Data from 2021: 6,071 (94.8%)\n",
      "‚ö†Ô∏è  Data NOT from 2021: 334 (5.2%)\n",
      "\n",
      "üìä Distribution of non-2021 data:\n",
      "year\n",
      "2022    248\n",
      "2023     53\n",
      "2024     33\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üìä 2021 Responses by Month:\n",
      "   April: 2,036\n",
      "   May: 3,040\n",
      "   June: 103\n",
      "   July: 66\n",
      "   August: 122\n",
      "   September: 48\n",
      "   October: 549\n",
      "   November: 63\n",
      "   December: 44\n",
      "\n",
      "\n",
      "üîç DATE FILTERING DECISION\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "‚ö†Ô∏è  Non-2021 data detected!\n",
      "\n",
      "üí° Decision: Filter to 2021 data only\n",
      "   Reason: Survey was conducted in 2021, other years likely errors or late submissions\n",
      "\n",
      "‚úÖ Filtered to 2021 data only\n",
      "   Rows before: 6,405\n",
      "   Rows after: 6,071\n",
      "   Rows removed: 334\n",
      "\n",
      "\n",
      "üìä FINAL TIMESTAMP SUMMARY\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìÖ Final Date Range:\n",
      "   Start: April 29, 2021\n",
      "   End: December 31, 2021\n",
      "   Total days: 246\n",
      "\n",
      "üìà Survey Response Timeline (by week):\n",
      "week\n",
      "17    2567\n",
      "18    2117\n",
      "19     228\n",
      "20      99\n",
      "21      63\n",
      "22      33\n",
      "23      32\n",
      "24      23\n",
      "25      13\n",
      "26      11\n",
      "dtype: int64\n",
      "\n",
      "‚úÖ Phase 8 Complete!\n",
      "‚ú® Cleaned dataset: 6,071 rows √ó 31 columns\n",
      "\n",
      "üìä New columns added:\n",
      "   - timestamp_dt (datetime)\n",
      "   - year, month, day, date (date components)\n",
      "   - week (week number)\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# PHASE 8: Date/Timestamp Filtering\n",
    "# ============================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"PHASE 8: DATE/TIMESTAMP FILTERING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ----------------\n",
    "# TIMESTAMP ANALYSIS\n",
    "# ----------------\n",
    "print(\"\\nüìÖ TIMESTAMP ANALYSIS\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Check current timestamp format\n",
    "print(\"\\nüìã Sample timestamp values:\")\n",
    "print(df_clean['timestamp'].head(10).tolist())\n",
    "\n",
    "print(f\"\\nüìä Timestamp column type: {df_clean['timestamp'].dtype}\")\n",
    "\n",
    "# Convert timestamp to datetime\n",
    "print(\"\\nüîÑ Converting timestamp to datetime...\")\n",
    "df_clean['timestamp_dt'] = pd.to_datetime(df_clean['timestamp'], errors='coerce')\n",
    "\n",
    "# Check for any conversion failures\n",
    "timestamp_conversion_failed = df_clean['timestamp_dt'].isna().sum()\n",
    "print(f\"   Conversion failures: {timestamp_conversion_failed:,}\")\n",
    "\n",
    "if timestamp_conversion_failed > 0:\n",
    "    print(\"\\n‚ö†Ô∏è  Sample of failed conversions:\")\n",
    "    failed_timestamps = df_clean[df_clean['timestamp_dt'].isna()]['timestamp'].head(10)\n",
    "    print(failed_timestamps.tolist())\n",
    "\n",
    "print(\"\\n‚úÖ Timestamp converted to datetime!\")\n",
    "\n",
    "# ----------------\n",
    "# DATE RANGE ANALYSIS\n",
    "# ----------------\n",
    "print(\"\\n\\nüìä DATE RANGE ANALYSIS\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Extract date components\n",
    "df_clean['year'] = df_clean['timestamp_dt'].dt.year\n",
    "df_clean['month'] = df_clean['timestamp_dt'].dt.month\n",
    "df_clean['day'] = df_clean['timestamp_dt'].dt.day\n",
    "df_clean['date'] = df_clean['timestamp_dt'].dt.date\n",
    "\n",
    "# Show date range\n",
    "min_date = df_clean['timestamp_dt'].min()\n",
    "max_date = df_clean['timestamp_dt'].max()\n",
    "\n",
    "print(f\"\\nüìÖ Survey Date Range:\")\n",
    "print(f\"   Earliest response: {min_date}\")\n",
    "print(f\"   Latest response: {max_date}\")\n",
    "print(f\"   Duration: {(max_date - min_date).days} days\")\n",
    "\n",
    "# Check year distribution\n",
    "print(\"\\nüìä Responses by Year:\")\n",
    "year_dist = df_clean['year'].value_counts().sort_index()\n",
    "print(year_dist)\n",
    "\n",
    "# Check if all data is from 2021\n",
    "data_2021 = (df_clean['year'] == 2021).sum()\n",
    "data_not_2021 = (df_clean['year'] != 2021).sum()\n",
    "\n",
    "print(f\"\\n‚úÖ Data from 2021: {data_2021:,} ({(data_2021/len(df_clean))*100:.1f}%)\")\n",
    "if data_not_2021 > 0:\n",
    "    print(f\"‚ö†Ô∏è  Data NOT from 2021: {data_not_2021:,} ({(data_not_2021/len(df_clean))*100:.1f}%)\")\n",
    "    print(\"\\nüìä Distribution of non-2021 data:\")\n",
    "    print(df_clean[df_clean['year'] != 2021]['year'].value_counts().sort_index())\n",
    "\n",
    "# Check month distribution (for 2021 data)\n",
    "print(\"\\nüìä 2021 Responses by Month:\")\n",
    "month_dist_2021 = df_clean[df_clean['year'] == 2021]['month'].value_counts().sort_index()\n",
    "for month_num, count in month_dist_2021.items():\n",
    "    month_name = pd.Timestamp(2021, month_num, 1).strftime('%B')\n",
    "    print(f\"   {month_name}: {count:,}\")\n",
    "\n",
    "# ----------------\n",
    "# DATE FILTERING DECISION\n",
    "# ----------------\n",
    "print(\"\\n\\nüîç DATE FILTERING DECISION\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "if data_not_2021 > 0:\n",
    "    print(\"\\n‚ö†Ô∏è  Non-2021 data detected!\")\n",
    "    print(\"\\nüí° Decision: Filter to 2021 data only\")\n",
    "    print(\"   Reason: Survey was conducted in 2021, other years likely errors or late submissions\")\n",
    "    \n",
    "    rows_before_date_filter = len(df_clean)\n",
    "    df_clean = df_clean[df_clean['year'] == 2021].copy()\n",
    "    rows_after_date_filter = len(df_clean)\n",
    "    rows_removed_date = rows_before_date_filter - rows_after_date_filter\n",
    "    \n",
    "    print(f\"\\n‚úÖ Filtered to 2021 data only\")\n",
    "    print(f\"   Rows before: {rows_before_date_filter:,}\")\n",
    "    print(f\"   Rows after: {rows_after_date_filter:,}\")\n",
    "    print(f\"   Rows removed: {rows_removed_date:,}\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ All data is from 2021 - no filtering needed!\")\n",
    "\n",
    "# ----------------\n",
    "# FINAL TIMESTAMP SUMMARY\n",
    "# ----------------\n",
    "print(\"\\n\\nüìä FINAL TIMESTAMP SUMMARY\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "final_min_date = df_clean['timestamp_dt'].min()\n",
    "final_max_date = df_clean['timestamp_dt'].max()\n",
    "\n",
    "print(f\"\\nüìÖ Final Date Range:\")\n",
    "print(f\"   Start: {final_min_date.strftime('%B %d, %Y')}\")\n",
    "print(f\"   End: {final_max_date.strftime('%B %d, %Y')}\")\n",
    "print(f\"   Total days: {(final_max_date - final_min_date).days}\")\n",
    "\n",
    "# Show response volume by week\n",
    "print(\"\\nüìà Survey Response Timeline (by week):\")\n",
    "df_clean['week'] = df_clean['timestamp_dt'].dt.isocalendar().week\n",
    "weekly_responses = df_clean.groupby('week').size().head(10)\n",
    "print(weekly_responses)\n",
    "\n",
    "print(\"\\n‚úÖ Phase 8 Complete!\")\n",
    "print(f\"‚ú® Cleaned dataset: {df_clean.shape[0]:,} rows √ó {df_clean.shape[1]} columns\")\n",
    "print(f\"\\nüìä New columns added:\")\n",
    "print(f\"   - timestamp_dt (datetime)\")\n",
    "print(f\"   - year, month, day, date (date components)\")\n",
    "print(f\"   - week (week number)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Business Questions Analysis\n",
    "\n",
    "Now answer those important business questions!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median salary for Software Engineers in the United States: $141,875.00\n",
      "Sample size: 234 Software Engineers\n"
     ]
    }
   ],
   "source": [
    "# Question 1: What is the median salary for Software Engineers in the United States?\n",
    "\n",
    "# Filter for Software Engineers in US\n",
    "q1_data = df_clean[\n",
    "    (df_clean['country'] == 'US') &\n",
    "    (df_clean['is_software_engineer'] == True)\n",
    "]\n",
    "\n",
    "# Calculate median salary\n",
    "median_salary = q1_data['salary'].median()\n",
    "\n",
    "# Answer\n",
    "print(f\"Median salary for Software Engineers in the United States: ${median_salary:,.2f}\")\n",
    "print(f\"Sample size: {len(q1_data):,} Software Engineers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US state with highest average salary for tech workers: California, Oregon\n",
      "Average salary: $200,000.00\n",
      "Sample size: 944 tech workers across 50 states\n"
     ]
    }
   ],
   "source": [
    "# Question 2: Which US state has the highest average salary for tech workers?\n",
    "\n",
    "# Filter for tech workers in US with valid state data\n",
    "q2_data = df_clean[\n",
    "    (df_clean['country'] == 'US') &\n",
    "    (df_clean['industry'] == 'Computing or Tech') &\n",
    "    (df_clean['state'].notna())\n",
    "]\n",
    "\n",
    "# Calculate average salary by state\n",
    "state_avg_salary = q2_data.groupby('state')['salary'].mean().sort_values(ascending=False)\n",
    "\n",
    "# Get the top state\n",
    "top_state = state_avg_salary.index[0]\n",
    "top_salary = state_avg_salary.iloc[0]\n",
    "\n",
    "# Answer\n",
    "print(f\"US state with highest average salary for tech workers: {top_state}\")\n",
    "print(f\"Average salary: ${top_salary:,.2f}\")\n",
    "print(f\"Sample size: {len(q2_data):,} tech workers across {len(state_avg_salary)} states\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average salary increase per year of experience in tech: $2,995.19\n",
      "Sample size: 958 tech workers\n"
     ]
    }
   ],
   "source": [
    "# Question 3: How much does salary increase on average for each year of experience in tech?\n",
    "\n",
    "# Filter for tech workers with valid experience data\n",
    "q3_data = df_clean[\n",
    "    (df_clean['industry'] == 'Computing or Tech') &\n",
    "    (df_clean['years_experience_field_num'].notna())\n",
    "]\n",
    "\n",
    "# Calculate correlation and average increase per year\n",
    "# Group by years of experience and get average salary\n",
    "exp_salary = q3_data.groupby('years_experience_field_num')['salary'].mean()\n",
    "\n",
    "# Calculate the slope (average increase per year) using simple linear relationship\n",
    "# This is the difference in average salary divided by difference in experience\n",
    "salary_per_year = (exp_salary.iloc[-1] - exp_salary.iloc[0]) / (exp_salary.index[-1] - exp_salary.index[0])\n",
    "\n",
    "# Answer\n",
    "print(f\"Average salary increase per year of experience in tech: ${salary_per_year:,.2f}\")\n",
    "print(f\"Sample size: {len(q3_data):,} tech workers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest paying industry (besides tech): Corporate Training\n",
      "Median salary: $280,000.00\n",
      "Sample size: 5,113 workers across 327 industries\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Question 4: What percentage of respondents work remotely vs. in-office?\n",
    "#I don't know if this is a trick question but the data doesn't exist for this question\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest paying industry (besides tech): Corporate Training\n",
      "Median salary: $280,000.00\n",
      "Sample size: 5,113 workers across 327 industries\n"
     ]
    }
   ],
   "source": [
    "# Question 5: Which industry (besides tech) has the highest median salary?\n",
    "\n",
    "# Filter for non-tech industries\n",
    "q5_data = df_clean[df_clean['industry'] != 'Computing or Tech']\n",
    "\n",
    "# Calculate median salary by industry\n",
    "industry_median_salary = q5_data.groupby('industry')['salary'].median().sort_values(ascending=False)\n",
    "\n",
    "# Get the top industry\n",
    "top_industry = industry_median_salary.index[0]\n",
    "top_median = industry_median_salary.iloc[0]\n",
    "\n",
    "# Answer\n",
    "print(f\"Highest paying industry (besides tech): {top_industry}\")\n",
    "print(f\"Median salary: ${top_median:,.2f}\")\n",
    "print(f\"Sample size: {len(q5_data):,} workers across {len(industry_median_salary)} industries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender pay gap in tech roles:\n",
      "  Men median salary: $135,000.00\n",
      "  Women median salary: $112,525.00\n",
      "  Pay gap: 16.6% (women earn 16.6% less than men)\n",
      "  Sample size: 921 tech workers (Men: 395, Women: 526)\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Master's vs Bachelor's degree salary comparison:\n",
      "  Bachelor's degree median salary: $74,000.00\n",
      "  Master's degree median salary: $85,000.00\n",
      "  Difference: $11,000.00 (14.9% higher with Master's)\n",
      "  Sample size: Bachelor's: 3,449, Master's: 1,913\n"
     ]
    }
   ],
   "source": [
    "# Bonus Question 5: What's the salary gap between men and women in tech roles?\n",
    "\n",
    "# Filter for tech workers with binary gender (Man or Woman)\n",
    "q6_data = df_clean[\n",
    "    (df_clean['industry'] == 'Computing or Tech') &\n",
    "    (df_clean['gender_standard'].isin(['Man', 'Woman']))\n",
    "]\n",
    "\n",
    "# Calculate median salary by gender\n",
    "gender_salaries = q6_data.groupby('gender_standard')['salary'].median()\n",
    "\n",
    "men_salary = gender_salaries['Man']\n",
    "women_salary = gender_salaries['Woman']\n",
    "\n",
    "# Calculate the gap (as percentage)\n",
    "pay_gap_percent = ((men_salary - women_salary) / men_salary) * 100\n",
    "\n",
    "# Answer\n",
    "print(f\"Gender pay gap in tech roles:\")\n",
    "print(f\"  Men median salary: ${men_salary:,.2f}\")\n",
    "print(f\"  Women median salary: ${women_salary:,.2f}\")\n",
    "print(f\"  Pay gap: {pay_gap_percent:.1f}% (women earn {pay_gap_percent:.1f}% less than men)\")\n",
    "print(f\"  Sample size: {len(q6_data):,} tech workers (Men: {(q6_data['gender_standard']=='Man').sum():,}, Women: {(q6_data['gender_standard']=='Woman').sum():,})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Bonus Question 6: Do people with Master's degrees earn significantly more than those with Bachelor's degrees?\n",
    "\n",
    "# Filter for Bachelor's and Master's degree holders\n",
    "q7_data = df_clean[\n",
    "    (df_clean['has_bachelors'] == True) | (df_clean['has_masters'] == True)\n",
    "]\n",
    "\n",
    "# Calculate median salary by education level\n",
    "bachelors_salary = df_clean[df_clean['has_bachelors'] == True]['salary'].median()\n",
    "masters_salary = df_clean[df_clean['has_masters'] == True]['salary'].median()\n",
    "\n",
    "# Calculate the difference\n",
    "salary_difference = masters_salary - bachelors_salary\n",
    "percent_increase = ((masters_salary - bachelors_salary) / bachelors_salary) * 100\n",
    "\n",
    "# Answer\n",
    "print(f\"Master's vs Bachelor's degree salary comparison:\")\n",
    "print(f\"  Bachelor's degree median salary: ${bachelors_salary:,.2f}\")\n",
    "print(f\"  Master's degree median salary: ${masters_salary:,.2f}\")\n",
    "print(f\"  Difference: ${salary_difference:,.2f} ({percent_increase:.1f}% higher with Master's)\")\n",
    "print(f\"  Sample size: Bachelor's: {df_clean['has_bachelors'].sum():,}, Master's: {df_clean['has_masters'].sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Summary\n",
    "\n",
    "**Summarize your findings here:**\n",
    "\n",
    "1. **Median salary for Software Engineers in US:** \n",
    "2. **Highest paying US state for tech:** California, Oregon\n",
    "3. **Salary increase per year of experience:** $2,995.19\n",
    "4. **Remote vs office percentage:** This data doesn't exist\n",
    "5. **Highest paying non-tech industry:** Corporate Training\n",
    "\n",
    "**Key insights:**\n",
    "- Specify where you want the code to be written, sometimes Claude decided I needed to do 2 tasks in one cell and another task across 3\n",
    "- At least have an idea on how the work should be done, I had to remind Claude to use regex instead of making a list of every possible way to describe \"US\"\n",
    "\n",
    "**Challenges faced:**\n",
    "- The data didn't exist within the survey responses about remote vs in-person work. I argued with Claude until I checked the dataset myself and realized this question was supposed to trip me up\n",
    "- For the answers to the questions, Claude made the code incredibly bloated. Almost as if we didn't just spend 45 minutes of my time together making the dataset easier to work with. I solved this by instructing the agent to not make things overly complicated and just answer the question with some basic context\n",
    "\n",
    "**What you learned about vibe coding:**\n",
    "- You will get very bored waiting for responses sometimes\n",
    "- I don't think my job is too much at risk anymore\n",
    "- Don't do it after already trying to watch a toddler at home, you will end up with a broken keyboard\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
